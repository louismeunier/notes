\documentclass[12pt,oneside]{article}
\usepackage{amsthm}
\usepackage{libertine}
\usepackage[margin=0.15in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{multicol}
\usepackage[shortlabels]{enumitem}
\usepackage{siunitx}
\usepackage{setspace}
\usepackage{cancel}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{listings}
\usepackage{tabularx}
\usepackage{titlesec}[pagestyles]
\usepackage{thmtools}
\usepackage{thm-restate}
\usepackage{xcolor-solarized}
\usepackage{footnote}
\usepackage[side, ragged]{footmisc}

\usepackage{marginnote}
\usepackage{xsim}
\usepackage[colorlinks=true, linkcolor=darkgray]{hyperref}
\usepackage[raggedrightboxes]{ragged2e}
\usepackage{cleveref}
\usepackage[]{csquotes}
\usepackage{shortcuts}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{stackengine}
\usepackage[createShortEnv]{proof-at-the-end}

\usepackage{xpatch}


% makes theorems, definitions, etc. "restatable" as shown
% can add more with same format as you wish
\renewcommand{\footnotesize}{\scriptsize}
% \renewcommand*{\proofname}{}
\renewcommand*{\qedsymbol}{\(\blacksquare\)}

\DeclareMathOperator*{\lcm}{lcm}
% TODO: subsection numbering

\declaretheorem[
  % thmbox=S,
  name=Remark,
  refname={Remark, remark},
  numberwithin=section
]{remark}

\mdfdefinestyle{example}{
  roundcorner=8pt,
  linecolor=white,
  leftmargin=15,rightmargin=15,
  backgroundcolor=solarized-cyan!20,
  skipabove=10pt, skipbelow=10pt,
  innertopmargin=2pt, innerbottommargin=5pt,
  innerleftmargin=8pt, innerrightmargin=8pt
}

\mdfdefinestyle{general-thm}{
  roundcorner=8pt,
  linecolor=white,
  % leftmargin=5,rightmargin=5,
  backgroundcolor=gray!10,
  skipabove=10pt, skipbelow=10pt,
  innertopmargin=2pt, innerbottommargin=5pt,
  innerleftmargin=8pt, innerrightmargin=8pt
}

\mdtheorem[style=example]{example}{$\circledast $ \underline{Example}}[section]

\mdtheorem[style=general-thm]{theorem}{\textcolor{solarized-red}{$\hookrightarrow$ \underline{Theorem}}}[section]

\mdtheorem[style=general-thm]{proposition}{\textcolor{solarized-magenta}{$\hookrightarrow $ \underline{Proposition}}}[section]
\mdtheorem[style=general-thm]{theorem}{\textcolor{solarized-red}{$\hookrightarrow$ \underline{Theorem}}}[section]
\mdtheorem[style=general-thm]{corollary}{\textcolor{solarized-orange}{$\hookrightarrow$ \underline{Corollary}}}[section]
\mdtheorem[style=general-thm]{lemma}{\textcolor{solarized-orange}{$\hookrightarrow$ \underline{Lemma}}}[section]
\mdtheorem[style=general-thm]{axiom}{\textcolor{solarized-orange}{$\hookrightarrow$ \underline{Axiom}}}[section]
\mdtheorem[style=general-thm]{definition}{\textcolor{solarized-blue}{$\hookrightarrow$ \underline{Definition}}}[section]


% grr broken references
\newcommand{\thmautorefname}{Theorem}
\makeatletter
\xpatchcmd{\theorem}{\refstepcounter}{\NR@gettitle{#1}\refstepcounter}{}{}
\makeatother
\newcommand{\propautorefname}{Proposition}
\makeatletter
\xpatchcmd{\proposition}{\refstepcounter}{\NR@gettitle{#1}\refstepcounter}{}{}
\makeatother

\usepackage{etoolbox}
\BeforeBeginEnvironment{theorem}{\savenotes}
\AfterEndEnvironment{theorem}{\spewnotes}


% makes "quoted" text actually look correct
\MakeOuterQuote{"}

% page footer
\newpagestyle{mypage}{%
    % \footrule
    \setfoot{\scriptsize\textcolor{gray}{ยง\ref{sec:\thesubsection}}}{\scriptsize\textcolor{gray}{\textit{\sectiontitle: \textbf{\subsectiontitle}}}}{\textcolor{gray}{\scriptsize p. \thepage}}
}


% make \part title smaller and inline
\titleformat{\part}[display]
{\normalfont\Large\bfseries}{\,}{0pt}{\thepart . \Large}

% title page settings
\newcommand{\pageauthor}{Louis Meunier}
\newcommand{\pagetitle}{Algebra I, II}
\newcommand{\pagesubtitle}{MATH235}

% black square for qed symbol
\renewcommand{\qedsymbol}{$\blacksquare$}

\titleformat{\section}
{\centering\normalfont\Large\bfseries}
{\thesection}{1em}{}

\begin{document}
\setstretch{2.25}
\noindent
\begin{center}
    \begin{tabularx}{\textwidth} { 
        >{\raggedright\arraybackslash}X 
        >{\raggedleft\arraybackslash}X}
    \LARGE \pageauthor \\
    \LARGE \textbf{\pagetitle} & \LARGE \textbf{\pagesubtitle}\\
    \end{tabularx}\\
    \rule[2ex]{0.8\textwidth}{1pt}
\end{center}

\setstretch{1.5}

\begin{mdframed}[backgroundcolor=gray!20]
  \underline{Course Outline:}\\
  \textit{Introductory abstract algebra. Sets, functions, relations. Methods of proof. Arithmetic on integers. Fields, rings; groups, subgroups, cosets.}
\end{mdframed}

\tableofcontents

% "enables" footer with section+subsection, etc. just comment it out if you don't want it
\pagestyle{mypage}

% makes sections a very dark gray + centered
\titleformat{\section}
{\color{darkgray}\centering\normalfont\Large\bfseries}
{\color{darkgray}\thesection}{1em}{}

% need to change margins and such here for rest of document
% kind of messy but what can you do

% modify these as you wish
\newgeometry{margin=0.25in, top=0.4in, bottom=0.5in, marginparwidth=1.4in, marginparsep=0.3in, outer=0.2in, includemp}
\setstretch{1.2}
\parskip=0.6em
% auto labelling for sections/subsections

\let\origsection=\section
\let\origsubsection=\subsection

\renewcommand\section[1]{\origsection{#1}\label{sec:\thesection}}
\renewcommand\subsection[1]{\origsubsection{#1}\label{sec:\thesubsection}}

\part{Fundamentals}

% quotation
\begin{displayquote}
  "It is intuitively obvious." - Anonymous
\end{displayquote}
\begin{displayquote}
  "Trivial" - Anonymous
\end{displayquote}
\section{Sets}
\subsection{Definition}
A \textbf{set} can be considered as a collection of elements; more intuitively, you can consider something a set if you can determine whether a given object belongs to it. Typically sets are defined as $A = \{1, 2, \dots\}$, by a property $A = \{x \,|\, x\%2 = 0\}$, or with an appropriate verbal description.

\subsection{Set operations}
There are a number of ways to "combine" sets:

\begin{itemize}
  \item \textbf{Union}: $A \cup B = \{x \,|\, x \in A \text{ or } x \in B\}$ 
  % \tikz \fill (0,0) circle (0.25) (0.25,0) circle (0.25);
  \item \textbf{Intersection}: $A \cap B = \{x \,|\, x \in A \text{ and } x \in B\}$ 
  \item \textbf{Difference}: $A \setminus B = \{x \,|\, x \in A \text{ and } x \notin B\}$ 
\end{itemize}

\begin{lemma}
  $A = (A\setminus B)\cup(A\cap B)$
\end{lemma}
\begin{proof}
  To prove set equivalencies, we must prove that both RHS $\subseteq$ LHS and LHS $\subseteq$ RHS; meaning, the LHS and RHS are subsets of each other, and are thus equal.
  
  First, to prove LHS $\subseteq$ RHS, let $a \in A$. If $a \notin B$, then $a \in A\setminus B$, and $a \in$ RHS. Else, if $a \in B$, then $a \in A \cap B$ and $a \in$ RHS. Thus, LHS $\subseteq$ RHS.

  Next, to prove RHS $\subseteq$ LHS, let $a \in $ RHS. If $a \in A \setminus B$, then $a \in A=$ LHS. Else, $a \in A \cap B$, and thus $a \in A=$ LHS. Thus, RHS $\subseteq$ LHS.
  Since LHS $\subseteq$ RHS and RHS $\subseteq$ LHS, LHS = RHS.
\end{proof}

\subsection{Indexed sets}

Let $I$ be a set. If for every $i \in I$, we have a set $B_i$, we say that we have a \textit{collection} of sets $B_i$ indexed by $I$. We write $\{B_i : i \in I\}$.

\begin{example}
  Let $I = \{1, 2, 3\}$, and $B_i = \{1,2,3,4\}\setminus \{i\}$ ($B_i$ is the set of all numbers from 1 to 4, excluding $i$), for $i \in I$. We thus have $B_1 = \{2, 3, 4\}$ (etc.).

  This concept of indexing allows us to introduce repeated unions/intersections. For instance, we can write \[\bigcup_{i \in I} B_i = B_1 \cup B_2 \cup B_3 = \{1,2,3,4\}.\]
  Similarly, \[\bigcap_{i \in I} B_i = \{4\}.\footnotemark\]
\end{example}
\footnotetext{You can somewhat consider these "large" unions/intersections as analogous to summations $\Sigma$ and products $\Pi$.}

\begin{example}
  Let $I = \mathbb{R}$, and $B_i = [i, \infty] = \{r \in \mathbb{R} : r \geq i\}$. Then, $\bigcup_{i \in \mathbb{R}} B_i = \mathbb{R}$ and $\bigcap_{i \in \mathbb{R}} B_i = \emptyset$.
\end{example}

\subsection{Cartesian product}

Let $A_1, A_2, \dots, A_n$ be sets. We define the \textbf{Cartesian product} \[A_1 \times A_2 \times \cdots \times A_n = \{(x_1, x_2, \dots, x_n) : x_i \in A_i, \text{ for } 1 \leq i \leq n\}.\] For instance, \[A \times B = \{(a, b) : a \in A, b \in B\}.\]

\begin{example}
  Let $A = B = \mathbb{R}$. $A \times B = \{(x,y) : x \in \mathbb{R}, y \in \mathbb{R} \} = \mathbb{R}^2$ is the set of all points in the Cartesian plane.
\end{example}

We can also define Cartesian products over an index set. Let $I$ be an index set, with $A_i$ for all $i \in I$. Then, we can write \[\prod_{i \in I}A_i = \{(a_i)_{i \in I} : a_i \in A_i\}\]

\begin{example}
  \begin{align*}
    I &= \mathbb{N}, A_0 = \{0, 1, 2, \dots\}, A_1 = \{1, 2, 3, \dots\}, ... , A_i = \{i, i+1, i+2, \dots \}\\
  Y &:= \prod_{i \in I}A_i = \{(a_0, a_1, a_2, \dots):a_i \in \mathbb{N}, a_i \geq i\}
  \end{align*}
  We can say that a particular vector $(b_0, b_1, \dots) \in Y$ if for each $b_i$, $b_i \geq i$ (and $b_i \in \mathbb{N}$, of course). In other words, a particular item of the vector must be greater than or equal to its index. Thus, we can say \[(0, 1, 2, 3, \dots) \in Y\] while \[(2,2,2, 2, \dots) \notin Y\] since $a_3 = 2 \implies i = 3$, and $2 \ngeq 3$.
\end{example}

\section{Methods of Proof}
\subsection{Proving equality via two inequalities}
In short, say $x, y \in \mathbb{R}$. $x = y \iff x \leq y \text{ and } y \leq x$. Similarly, in the context of sets, we can say that, for two sets $X, Y$, $X = Y \iff X \subseteq Y \text{ and } Y \subseteq X$.

\subsection{Contradiction (bwoc)}

Given a statement $P$, we can prove $P$ true by assuming $P$ false ($\equiv \neg P$), then arriving to a contradiction (this contradiction is often a violated axiom or basic rule of the system at hand.)
\begin{example}
Show that there are no solutions to $x^2 - y^2 = 1$ in the positive integers.
\begin{proof}[Proof (bwoc)] Assume there are, so $x, y \in \mathbb{Z}_+$.\footnotemark We can then write \[1 = x^2 - y^2 = (x-y)(x+y).\] $x-y$ and $x+y$ must be integers, and so we have two cases, $\begin{cases}
  x-y = 1\\
  x+y = 1
\end{cases}$ and $\begin{cases}
  x-y = -1\\
  x+y = -1
\end{cases}$. In either case, $y$ must be zero, contradicting our initial assumption and thus proving the statement.
\end{proof}
\end{example}

\footnotetext{$\mathbb{Z}_+$ is used to denote positive integers; similarly, $\mathbb{Z}_-$ denotes negative integers.}

\subsection{Proving the contrapositive}
Logically, $A \implies B \iff \neg B \implies \neg A$\footnote{"I am hungry therefore I will eat" $\iff$ "I will \textit{not} eat therefore I am \textit{not} hungry." Notice too that $B$ need not imply $A$ ("I will eat therefore I am hungry"). If $A \implies B \iff B \implies A$, $A \equiv B$}.

\begin{example}
  Let $X,Y$ be sets. Prove $X = X\setminus Y \implies X \cap Y = \emptyset$.
  \begin{proof}
    Prove contrapositive: $X \cap Y \neq \emptyset \implies X \neq X \setminus Y$. $X \cap Y \neq \emptyset \implies \exists t \in X \cap Y \implies t \in X \text{ and } t \in Y$, thus $t \notin X\setminus Y$, but $t \in X$, so $X \neq X \setminus Y$.
  \end{proof}
\end{example}

\subsection{Induction}

\begin{axiom}[Well-Ordering Principle]
  Every $S \subseteq \mathbb{N}$, where $S \neq \emptyset$, has a minimal element, ie $\exists a \in S \text{ s.t. } \forall b \in S, a \leq b$.
\end{axiom}

% \newpage % not sure why everything's breaking
\begin{theorem}[Principle of Induction]
  Let $n_0 \in \mathbb{N}$. Say that for every $n \in \mathbb{Z}, n \geq n_0$, we are given a statement $P_n$. Assume
  \begin{enumerate}[label=(\alph*)]
    \item $P_{n_0}$ is true
    \item if $P_n$ is true, then $P_{n+1}$ is true
  \end{enumerate}
  then $P_n$ is true for all $n \geq n_0$.
\end{theorem}

\begin{proof}[Proof (bwoc)]
 Assume not.\footnote{note that (a) and (b) of the Principle of Induction are still taken to be true; it is simply the conclusion that is assumed to be false. } Then, we define $S = \{n \in \mathbb{N} : n \geq n_0, P_n \text{ false}\}$. By the Well-Ordering Principle, there exists a minimal element $a \in S$. By definition, $a \geq n_0$, and as $P_{n_0}$ is taken to be true, then $a > n_0$ since $n_0 \notin S$. Thus, $a-1 \notin S$, as $a$ is the minimal element of $S$, and therefore $P_{a-1}$ is true. However, by (b), this implies $P_{a}$ is also true, and thus $a \notin P$, contradicting our initial assumption.
\end{proof}

\subsection{Pigeonhole principle}
\begin{axiom}
  If there are more pigeons than pigeonholes, then at least one pigeonhole must contain more than one pigeon.\footnotemark
\end{axiom}
\footnotetext{Alternatively, you can consider fractional pigeons (though a little gruesome); given $n + 1$ pigeons and $n$ holes, each hole will contain, on average, $1 + \frac{1}{n}$ pigeons.}

\begin{example}
  Consider $n_1, \dots, n_6 \in \mathbb{N}$. There exist at least two of these $n$'s s.t. $n_i - n_j$ is evenly divisible by 5.
  \begin{proof}
    Let us rewrite each $n_i$ as $n_i = 5k_i + r_i$, where $k_i, r_i \in \mathbb{N}$, $k_i$ is the quotient, and $r_i$ is the residual. $r_i \in \{0, 1, 2, 3, 4\}$ (the only possible remainders when a number is divided by 5), and so there are 5 possible values of $r_i$, but 6 different $n_i$. Thus, two $n_i$ must have the same $r_i$, and we can write: 
    \begin{align*}
      n_i = 5k_i + r; &n_j = 5k_j + r\\
      n_i - n_j &= (5k_i + r) - (5k_j + r)\\
      &= 5(k_i-k_j)
    \end{align*}
    $(k_i - k_j) \in \mathbb{Z}$, and so $n_i - n_j$ is evenly divisible by 5. 
  \end{proof}
\end{example}

\section{Functions}

\subsection{Types of Functions}
\begin{definition}[Function]
  Given 2 sets $A, B$, a \emph{function} $f: A \to B$ is a rule such that $\forall a \in A, \exists! f(a) \in B$, where $\exists!$ denotes "there exists a unique".
  
\end{definition}

\begin{definition}[Graph]
  Given a function $f: A \to B$, a \emph{graph} $\Gamma_f = \{(a,f(a)) : a \in A\} \subseteq A \times B$. We can say that, $\forall a \in A$, $\exists! b \in B$ such that $(a,b) \in \Gamma_f$.
\end{definition}

\begin{example}
  Consider the Cartesian plane, denoted $\mathbb{R}^2$. It is simply a graph $\Gamma_f$ where $f: \mathbb{R} \to \mathbb{R}$ is the identity function, $f(x) = x$.
\end{example}

\begin{definition}[Injective]
  A function is an \emph{injection} iff $\forall a_1, a_2 \in A, f(a_1) = f(a_2) \implies a_1 = a_2$.
\end{definition}

\begin{definition}[Surjective]
  A function is a \emph{surjection} iff $\forall b \in B, \exists a \in A$ such that $f(a) = b$. In other words, every element of $B$ is mapped to by at least one element of $A$; you can pick any element in the range and it will have a preimage.
\end{definition}

\begin{definition}[Bijective]
  Both.
\end{definition}

\begin{definition}[Fibre]
The fibre of some $y \in Y$ is $f^{-1}({y}) = f^{-1}(y)$
\end{definition}

\subsection{Cardinality}
\begin{definition}[Cardinality]
  The \emph{cardinality} of a set $A$, denoted $|A|$, is the number of elements in $A$, if $A$ is finite, or a more abstract notion of size if $A$ is infinite.
\end{definition}

We say that two sets $A, B$ have the same cardinality ($|A|=|B|$) if $\exists$ a bijection $f: A \to B$.\footnote{Consider this in the finite case: a bijection indicates that all elements in the domain map uniquely to a single element in the range, and the range is completely "covered" sts by the function.}This necessitates the question, however: if two sets are not equal in cardinality, how do we compare their sizes?

We write 
\[|A| \leq |B| \impliedby \exists f : A \to B \text{ where } f \text{ is } \textit{injective}\]

and 

\[|A| \geq |B| \impliedby \exists f: A \to B \text{ where } f \text{ is } \textit{surjective.}\footnotemark\] Note that $|B| \leq |A|$ if either $A = \varnothing$ or, as above, $\exists f: B \to A$ surjective.
\footnotetext{Consider this intuitively; if your domain is smaller than your range, then you will "run out" of things to map from the domain to the range before you "run out" of things in the range, hence, you have a injection. Similarly, if your domain is larger than your range, then you will have "leftover" elements in the domain (that will map to "already mapped to" elements in the range), hence, you have a surjection.}

\begin{definition}[Composition]
  Given two functions $f: A \to B$, $g: B \to C$, the \emph{composition} is the function $g \circ f : A \to C$
\end{definition}
  
\begin{proposition}
  If $|A| = |B|$ and $|B| = |C|$ then $|A|=|C|$
\end{proposition}

\begin{proof}
  $\exists f: A \to B$ bijective, and $\exists g: B \to C$ bijective. We desire to show that $\exists h : A \to C$ that is bijective. We can write $h = g \circ f$, where $h(a) = g(f(a))$. 

  To show that $h$ bijective:
  \begin{itemize}
    \item \textbf{injective:} Suppose $h(a_1) = h(a_2)$, then $g(f(a_1)) = g(f(a_2))$, and since $g$ is injective, $f(a_1) = f(a_2)$. Since $f$ is injective, $a_1 = a_2$, and thus $h$ is injective.
    \item \textbf{surjective:} Let $c \in C$. Since $g$ is surjective, $\exists b \in B$ such that $g(b) = c$. Since $f$ is surjective, $\exists a \in A$ such that $f(a) = b$. Thus, $h(a) = g(f(a)) = g(b) = c$, and thus $h$ is surjective.
  \end{itemize}
  Thus, $h$ is bijective, and $|A|=|C|$.
\end{proof}

\begin{lemma}
  If $g \circ f$ injective, $f$ injective. If $g \circ f$ surjective, $g$ surjective.
\end{lemma}

\begin{definition}[Image]
  The \emph{image} of a function $f: A \to B$ is the set $\text{Im}(f) = \{f(a) : a \in A\}$, ie the set of all elements in $B$ that are mapped to by $f$. Note that $\text{Im}(f) \subseteq B$, and $\text{Im}(f) = B$ if $f$ is surjective.
\end{definition}

\begin{proposition}
  $|A|\leq |B|$if $ |B| \geq |A|$  
\end{proposition}
  
\begin{proof}
  If $A = \varnothing$, $|B|\geq |A|$ clearly.

  If $A \neq \varnothing$, we are given $\exists f: A \to B$ injective. Let us choose some $a_0 \in A$. We define $g: B \to A$ as \[g(b) = \begin{cases}
    a_0 & b \notin \text{Im}(f)\\
    a & b =f(a)\in \text{Im}(f)\footnotemark
  \end{cases}\] Note that $g(f(a)) = g(b) = a$, so $g$ is surjective. Thus, $|B| \geq |A|$.
  \footnotetext{Note that $a$ is unique in $A$, as $f$ is injective.}
\end{proof}

\begin{proposition}
  $|B|\geq |A|$ if $|A|\leq |B|$
\end{proposition}

% \newpage
\begin{theorem}[Cantor-Bernstein Theorem]
  $|A| \leq |B| \text{ and } |B| \leq |A| \implies |A| = |B|$.
  \footnotemark

  Equivalently, if $\exists f: A \to B$ injective and $\exists g: B \to A$ injective, then $\exists h: A \to B$ bijective.
\end{theorem}
\footnotetext[9]{It is often very difficult to define an arbitrary bijective function between two sets in order to prove their cardinality is equal. The Cantor-Bernstein Theorem allows us to prove that two sets have the same cardinality by proving that there exists an injection from $A$ to $B$ and an injection from $B$ to $A$, which is typically far easier.}

\begin{proposition}
  If $|A_1|=|A_2|$ and $|B_1|=|B_2|$ then $|A_1 \times B_1| = |A_2 \times B_2|$.
\end{proposition}
\begin{proof}
  The first two statements define bijections $f: A_1 \to A_2$ and $g: B_1 \to B_2$, and we desire to have $f \times g:  A_1 \times B_1 \to A_2 \times B_2$. We define $f\times g(a_1, b_1) := (f(a_1), g(b_1))$. We must show that $f \times g$ is bijective.
  % TODO exercise
\end{proof}

\begin{example}
  Consider $A$ as the set of all points in the unit circle centered at $(0,0)$ in $\mathbb{R}^2$, and $B$ as the set of all points in the square of side length 2 centered at $(0,0)$ in $\mathbb{R}^2$ (ie, the circle is inscribed in the square). We wish to prove that $|A|=|B|$.
  \begin{proof}
    Let $f: A \to B$, $f(x) = x$. $f$ is injective, and thus $|A|\leq|B|$. 
    Let $g: A \to B$, $g(x) = \begin{cases}
      0; \sqrt{2}x \notin B\\
      \sqrt{2}x; \sqrt{2}x \in B
    \end{cases}$. In simpler terms, consider this as multiplying points of $A$ by $\sqrt{2}$; any point in this new "expanded" circle that lies within $B$ maps to itself, and any that lies outside maps to 0. This is thus a surjection, and thus $|B| \leq |A|$. By the Cantor-Bernstein Theorem, $|A|=|B|$.
  \end{proof}
\end{example}

\begin{proposition}
  $A = \{0, 1, 4, 9, \dots\}$. $|A| = |\mathbb{N}|$.
\end{proposition}

\begin{proof}
  Define $f: \mathbb{N} \to A$, $f(n) = n^2$. This is clearly injective \footnote{Notice that $f$ is only injective if we restrict the domain to $\mathbb{N}$; if we were to consider $\mathbb{Z}$, for instance, $f(-1) = f(1) = 1$.}, and thus $|A| \leq |\mathbb{N}|$.
\end{proof}

\begin{definition}[Countable/enumerable]
  A set $A$ is \emph{countable} if $|A| = |\mathbb{N}|$, or $A$ is finite. 
  
  If $A$ is finite of size $n$, $\exists$ a bijection $f: \{0,1,2,\dots,n-1\} \to A$. 
  
  If $A$ is infinite, $\exists$ a bijection $f: \mathbb{N} \to A$.
\end{definition}

\begin{proposition}
  $|\mathbb{N}|=|\mathbb{Z}|$
\end{proposition}

\begin{proof}
  We aim to find a bijection $f: \mathbb{Z} \to \mathbb{N}$, ie one that maps integers to natural numbers. Consider the function \[f(x) = \begin{cases}
    2x & x \geq 0\\
    -2x-1 & x < 0
  \end{cases}.\]
  % TODO: add graph
  This function is an injection because if $f(x_1)=f(x_2)$, then $x_1 = x_2$ (positive case: $2x_1 = 2x_2 \implies x_1 = x_2$, negative case: $-2x_1-1 = -2x_2-1 \implies x_1 = x_2$, and $2x_1 \neq -2x_2 - 1$ for any integer). It is also a surjection (there is no natural number that cannot be mapped to by an integer). Thus, the function is a bijection and $|\mathbb{N}|=|\mathbb{Z}|$. \footnote{Note what would happen if $f$ was defined as $-2x$ for $x<0$; then, $f$ would not be surjective (eg, $f(-1) = 2 = f(1)$.)}
\end{proof}

\begin{proposition}
  $|\mathbb{N}|=|\mathbb{N}\times\mathbb{N}|$
\end{proposition}

\begin{remark}
  It is possible to construct a bijective $f: \mathbb{N} \times \mathbb{N} \to \mathbb{N}$; see assignment 1. % TODO: update reference
\end{remark}
\begin{proof}
  Let $f: \mathbb{N} \to \mathbb{N} \times \mathbb{N}, f(n) = (n,0)$, clearly an injection ($\implies |\mathbb{N}| \leq |\mathbb{N} \times \mathbb{N}|$)\footnote{Note that this function is \textit{not} surjective!}. The function $g(m,n) = 2^n 3^m$ is also injective, and thus $|\mathbb{N}| = |\mathbb{N}\times\mathbb{N}|$.
\end{proof}

\begin{corollary}\label{cor:yummycor}
  $|\mathbb{Z}|=|\mathbb{Z}\times\mathbb{Z}|$
\end{corollary}
\begin{proof}
  Consider $h: \mathbb{N} \to \mathbb{N}\times\mathbb{N}$, a bijection\footnote{Which must exist by the proof of the previous proposition.}, and $f: \mathbb{N} \to \mathbb{Z}$. Let $g=(f,f): \mathbb{N}\times\mathbb{N}\to\mathbb{Z}\times\mathbb{Z}$. The composition $g \circ h \circ f^{-1}: \mathbb{Z} \to \mathbb{N} \to \mathbb{N}\times \mathbb{N} \to \mathbb{Z} \times \mathbb{Z}$ is also a bijection, and thus $|\mathbb{Z}|=|\mathbb{Z}\times\mathbb{Z}|$.
\end{proof}

\begin{example}
  Show that $|\mathbb{N}|=|\mathbb{Q}|$.
  \begin{proof}
    First, we find an injection $\mathbb{Q} \to \mathbb{N}$. Let $f: \mathbb{Q} \to \mathbb{Z} \times \mathbb{Z}, f(n) = (p,q)$ where $\frac{p}{q} = n$ (by definition of $\mathbb{Q}$). Using the same function definitions as in \cref{cor:yummycor}, the composition $h^{-1}\circ g^{-1}\circ f: \mathbb{Q} \to \mathbb{Z}\times \mathbb{Z} \to \mathbb{N}\times\mathbb{N} \to \mathbb{N}$. This is a composition of injections, and is thus an injection itself, and thus $|\mathbb{Q}|\leq|\mathbb{N}|$. The identity function $1:\mathbb{N} \to \mathbb{Q}, 1(n) = n$ is clearly an injection as well as all naturals are rationals, and thus $|\mathbb{N}|\leq|\mathbb{Q}|$. By the Cantor-Bernstein Theorem, $|\mathbb{N}|=|\mathbb{Q}|$.
  \end{proof}
\end{example}

\begin{definition}
  We say $|A| < |B|$ if $|A| \leq |B|$ but $|A| \neq |B|$, ie $\exists f : A \to B$ is injective, but no such bijective.
\end{definition}

\begin{remark}
  We denote an injective function as $\mathbb{N} \hookrightarrow \mathbb{Z}$, and a surjective function as $\mathbb{Z} \twoheadrightarrow \mathbb{N}$. We say that a particular element $n$ maps to some other element $n'$ by $n \mapsto n'$
\end{remark}
\begin{theorem}[Cantor]
  $|\mathbb{N}|<|\mathbb{R}|$
\end{theorem}
\begin{proof}[Proof (Cantor's Diagonal Argument)]
  We clearly have an injection $\mathbb{N} \hookrightarrow \mathbb{R}, n \mapsto n$, thus $|\mathbb{N}|\leq|\mathbb{R}|$. 
  
  Now, suppose $|\mathbb{N}|=|\mathbb{R}|$. Then, we can enumerate the real numbers as $a_0, a_1, \dots$ with signs $\epsilon_i$. We denote the decimal expansion of each number as\footnotemark \begin{align*}
    a_0 &= \epsilon_0 0.a_{00}a_{01}a_{02}\dots\\
    a_1 &= \epsilon_1 0.a_{10}a_{11}a_{12}\dots\\
    a_2 &= \epsilon_2 0.a_{20}a_{21}a_{22}\dots\\
    &\vdots
  \end{align*} Consider the number $0.e_0e_1e_2\dots$, where $e_i = \begin{cases}
    3 & a_{ii} \neq 3\\
    4 & a_{ii} = 3
  \end{cases}.$ This number is different than any given $a_i$ at the $i+1$-th decimal place, and is thus not in the enumeration, contradicting our initial assumption.
\end{proof}
\footnotetext{We make the clarification that, despite the fact that $1.000\dots = 0.999\dots$, we will take the "infinite zeroes" interpretation, and thus every real number has a unique decimal expansion. This is an important, if subtle, distinction.}

\begin{remark}[Continuum Hypothesis]
  Cantor claimed that there's no set $|A|$ such that $|\mathbb{N}| < |A| < |\mathbb{R}|$. It has been proven today that this is "undecidable".
\end{remark}

\begin{definition}[Algebra on Cardinalities]
If $\alpha, \beta$ are cardinalities $\alpha = |A|, \beta = |B|$, Cantor defined:
\begin{align*}
  \alpha + \beta &= |A \sqcup B| \text{ (disjoint union)}\\ 
  \alpha \cdot \beta &= |A \times B|\\
  \alpha^\beta &= |B^A| \text{ (set of all functions from $A$ to $B$)}  
\end{align*}
\end{definition}

\section{Relations}
\subsection{Definitions}
\begin{definition}[Relation]
  A \emph{relation} on a set $A$ is a subset $S \subseteq A \times A (= \{(x,y) : x, y \in A\})$.

  We say that $x$ is \emph{related} to $y$ if $(x,y) \in S$, where we denote $x \sim y$. 

  Conversely, if we are given $x \sim y$, we can define an $S = \{(x,y): x \sim y\}$.
\end{definition}

\begin{example}
  Following are examples of relations on $A$.
  \begin{enumerate}[label=\arabic*)]
    \item Let $S = A \times A$; any $x \sim$ any $y$ because $(x,y) \in S$ for all $(x,y)$.
    \item Let $S = \varnothing$; no $x \sim$ any $y$ (even to itself).
    \item $S = \text{diag.} = \{(a,a) : a \in A\}$; $x \sim x \forall x$, but $x \nsim y$ if $y \neq x$.
    \item $A = [0,1] (\in \mathbb{R})$. Say $x \sim y$ if $x \leq y$. Thus, $S = \{(x,y) : x \leq y\}$ (the diagonal, and everything above).
    \item $A = \mathbb{Z}$, $x \sim y$ if $5 | (x-y)$, ie $x$ and $y$ have same residue mod 5.\footnotemark
  \end{enumerate}
\end{example}
\footnotetext{Where $a|b$ denotes that $b$ divides $a$.}

\begin{definition}[Reflexive]
  A relation is \emph{reflexive} if for any $x \in A$, $x \sim x$. 
  
  This includes examples 1), 2) (iff $A$ is empty), 3), 4), and 5) above.
\end{definition}

\begin{definition}[Symmetric]
  A relation is \emph{symmetric} if $x \sim y \implies y \sim x$.

  This includes 1), 2), 3), and 5) above.
\end{definition}

\begin{definition}[Transitive]
  A relation is \emph{transitive} if $x \sim y$ and $y \sim z$ implies $x \sim z$.

  This includes 1), 2), 3), 4), and 5) above.
\end{definition}
\subsection{Orders, Equivalence Relations and Classes, Partitions}
\begin{definition}[Partial Order]
  A \emph{partial order} on a set $A$ is a relation $x \sim y$ s.t.
  \begin{enumerate}
    \item $x \sim x$ \textit{(reflexive)}
    \item if $x \sim y$ and $y \sim x$, $x = y$ \textit{(antisymmetric)}
    \item $x \sim y$ and $y \sim z \implies x \sim z$ \textit{(transitive)}
  \end{enumerate}
  It is common to use $\leq$ in place of $\sim$ for partial orders.

  We call a set on which a partial order exists a \emph{partially ordered set} (poset).

  This is called partial, as it is possible that for some $x,y \in A$ we have $x \nsim y$ and $y \nsim x$, ie $x,y$ are not comparable. A partial order is called \emph{linear/total} if for every $x,y\in A$, either $x \leq y$ or $y \leq x$, eg., $A = [0,1], \mathbb{R}, \mathbb{Z}, \dots$, with $x \leq y$. Consider the above examples:

  \begin{itemize}
    \item[1)] is \emph{not} total, if $A$ has at least two element, because $\exists x \neq y$ but both $x \sim y$ and $y \sim x,$ and thus not antisymmetric.
    \item[3)] yes
    \item[5)] no, as this is symmetric, since $5 | (x-y) \implies 5 | (y-x)$, and thus $x \sim y, y \sim x \cancel{\implies} y = x$
  \end{itemize}
\end{definition}

\begin{example}
  Let\footnotemark $A = \mathbb{N}_+ = \{1, 2, 3, 4 \dots\},$ and define $a \sim b$ if $a|b$. We verify:
  \begin{itemize}
    \item $a \sim a$ (since $a|a$)
    \item $a\sim b, b \sim a \implies a = b$, since in $\mathbb{N}_+$, $a|b \implies a \leq b$, and we thus have $a \leq b$ and $b \leq a$, and thus $a = b$.
    \item suppose $a \sim b$ and $b \sim c$, then $a|b$ and $b|c$. We can write $b = a\cdot m$ and $c = b\cdot n$ for $n,m \in \mathbb{N}$. This means that $c = bn = amn = a(mn)$, which means that $a|c$, so $a \sim c$.
  \end{itemize}
  Thus, A is a poset. Note that this is not a linear order, as $2 \nsim 3$, and $3 \nsim 2$ (not all $a,b$ are comparable).
\end{example}
\footnotetext{Try this with integers, see where it fails}

\begin{definition}[Equivalence Relation]
  We aim to, abstractly, define some $\sim$ such that if $x \sim x, x \sim y$, then $y\sim x$, and if $x \sim y, y \sim z$, then $x \sim z$.

  Specifically, an equivalence relation $\sim$ on the set $A$ is a relation $x \sim y$ s.t. it is
  \begin{itemize}
    \item reflexive;
    \item symmetric;
    \item transitive.\footnotemark
  \end{itemize}
\end{definition}
\footnotetext{Note that, generally, equivalence and order relations are very different.}

\begin{example}\label{example:equiv1}
\begin{enumerate}
  \item Let $n \geq 1$ be an integer. A \emph{permutation} $\sigma$ of $n$ elements is a bijection $\sigma: \{1, 2, \dots, n\} \to \{1, 2, \dots, n\}$. Their number is $n!$, ie there are $n!$ permutations of $n$ elements. The collection of all permutations of $n$ elements is denoted $S_n$, which we call the "symmetric group" on $n$ elements. We aim to define an equivalence relation on $S_n$.
  
  Let us define $\sigma \sim \tau$ if $\sigma(1) = \tau(1)$. We verify that this is an equivalence relation:
  \begin{enumerate}
    \item $\sigma \sim \sigma$, $\sigma(1)=\sigma(1)$, so yes
    \item $\sigma \sim \tau$ means $\sigma(1) = \tau(1)$, so yes
    \item $\sigma \sim \tau, \tau \sim \rho$, $\sigma(1) = \tau(1), \tau(1) = \rho(1)$, so $\sigma(1) = \rho(1)$, hence $\sigma \sim \rho$, so yes.
  \end{enumerate}
  Thus, $\sim$ is an equivalence relation on $S_n$.
\end{enumerate}  
\end{example}

\begin{example}\label{example:equiv2}
  Define a relation on $\mathbb{Z}$ by saying that $x \sim y$ if $x-y$ even, ie $2|(x-y)$. This is reflexive, as $2|(x-x) = 0, x \sim x$, symmetric, since $(y-x) = -(x-y)$, and transitive $x-z = \underbrace{(x-y)}_{\text{even}}+\underbrace{(y-z)}_{\text{even }} \implies x \sim z$.
\end{example}

\begin{example}\label{example:equiv3}
  We say two sets $A \sim B$ if $|A| = |B|$. $1_A = \text{Id}: A \to A, a \mapsto a$ shows $A \sim A$. $A \sim B \implies \exists f: A \to B$ bijective, then $f^{-1}: B \to A$ also bijective so $B \sim A$. If $A \sim B, B \sim A$ then $A \sim C$ (since $|A| = |B|, |B| = |C| \implies |A| = |C|$ as proved earlier).
\end{example}

\begin{definition}[Disjoint Union]
  Let $S$ be a set, and $S_i, i \in I, \subseteq S$. $S$ is the \emph{disjoint union} of the $S_i$'s if $S = \cap_{i \in I} S_i$, and for any $i \neq j$, $S_i \cap S_j = \varnothing$\footnotemark; we denote 
  \(S = \amalg_{i \in I} S_i.\)
  We can say that $\{S_i\}$ for a \emph{partition} of $S$.
\end{definition}
\footnotetext{ie, no $S_i$'s share elements; think of "partitioning" $S$ such that no subsets overlap.}

\begin{example}
  Let $S = \{1,2\}$. Partitions are $\{1,2\}$, and $\{1\}, \{2\}$. 

  Let $S = \{1,2,3\}$. Partitions are $\{1,2,3\}$, $\{1\}, \{2\},\{3\}$, \dots
\end{example}

\begin{definition}[Equivalence Class]
  Given an equivalence relation $\sim$ of $A$ and some $x \in A$, the \emph{equivalence class} of $x$ is $[x] = \{y \in A : x \sim y\} \subseteq S$.
\end{definition}

\begin{theorem}\label{thm:equivclass}
  The following theorems are related to equivalence classes:
  \begin{itemize}
    \item[(1)] the equivalence classes of $A$ form a partition of $A$;
    \item[(2)] conversely, any partition of $A$ defines an equivalence relation on $A$ given by the partition.
  \end{itemize}
\end{theorem}

\begin{lemma}\label{lemma:subequiv}
  Let $X$ be an equivalence class; $a \in X$, then $X = [a]$.
\end{lemma}
\begin{proof}[Proof of \cref{lemma:subequiv}]
  If $X$ is an equivalence class, $X = [x]$ for some $x \in A$, by definition. Let $a \in X$. If $b \in [a]$ then $b \sim a$ and as $a \in [x]$ then $a \sim x \implies b \sim x \implies b \in [x] \implies [a] \subseteq [x]$.

  Otoh, $a \sim x \implies x \in [a]$, so $[x] \subseteq [a]$, and thus $[x] = [a]$.
\end{proof}

\begin{proof}[Proof of \cref{thm:equivclass}]
  We prove (1), (2) individually.

 (1) We aim to show that if the equivalence classes are $\{X_i\}_{i \in I}$ then $A = \amalg_{i \in I} X_i$. We say the following:
 \begin{itemize}
  \item[1.] Every $a \in A$ is in some equivalence class ($a \in [a]$).
  \item[2.] Two different equivalence classes are disjoint $\iff$ if $X,Y$ equiv. classes s.t. $X \cap Y \ne \varnothing$ then $X = Y$.\footnotemark
 \end{itemize}

 Let $a \in X \cap Y \overset{\text{lemma}}{\implies} [a] = X, [a] = Y \implies X = Y$.

 Here, consider the examples above;
 \begin{itemize}
  \item[-]\cref{example:equiv1}; $S_n$: there are $n$ equiv classes $X_i = \{\sigma \in S_n : \sigma(1) = i\}$. $S_n = X_1 \sqcup X_2 \sqcup \dots X_n$. $\sigma \in S_n$ and $\sigma(1) = i$, then $\sigma \in X_i$.
  \item[-] \cref{example:equiv2}; $\mathbb{Z}$: two equiv. classes; $X = \text{even integers} = [0]$, $Y = \text{odd integers} = [1]$, so $\mathbb{Z} = \text{even} \sqcup \text{odd}$
  \item[-] \cref{example:equiv3}; sets: an equivalence \textit{is} a cardinality. $n:=[\{1,2, \dots n\}] = $ all sets with $n$ elements. Similarly, we often write that $\aleph_0 := [\mathbb{N}] =$ inf. countable sets = sets un bijection with $\mathbb{N}$, and $2^{\aleph_0} := [\mathbb{R}]$.
 \end{itemize}

 (2) We are given a partition $A = \amalg_{i \in I} X_i$. We say $x \sim y$ if $\exists i \in I$ s.t. $x$ and $y$ belong to $X_i$ (noting that such an $i$ is unique if it exists by definition of a partition).

 \begin{itemize}
  \item $x\sim x$, clearly, since $x \in X_i \implies x \in X_i$
  \item $x \sim y \implies y \sim x$, by similar logic
  \item $x \sim y, y \sim z$ means that $x$ and $y$ in some same $X_i$, and $y$ and $z$ in some same $X_j$. So, $y \in X_i \cap X_j$, but we are working with a partition so $X_i$ and $X_j$ are disjoint and so this intersection is either $\varnothing$, or the sets are equal; since we know it is not empty, $X_i = X_j$, and so $x \sim z$.
 \end{itemize}

 Thus, $\sim$ is an equivalence relation.\footnotemark
\end{proof}
\footnotetext{Contrapositive...}
\footnotetext{This whole proof/theorem can sound pretty confusing. Abstractly, and non-rigorously, consider this: we define some "notion" of equivalence. Intuitively, if a set of items in, say, $A$, are equivalent, then they shouldn't be equivalent to any other items outside of that set (by our particular definition of equivalence). Thus, no "subsetting" of $A$ into equivalence classes will cause any subset to overlap; thus, we have a partition. This works in reverse through similar logic, where we even more concretely say that the very act of begin in the same partitioning of $A$ is to be equivalent.}

\begin{example}
  Let $A = $ students in this class. $x \sim y$ if $x, y$ have the same birthday. The equivalence classes in this case are the dates s.t. $\exists$ some student with that birthday.
\end{example}

\begin{definition}[Complete set of representatives]
  If $~$ is an equiv. relation on $A$, a subset $\{a_i : i \in I\}\subseteq A$ is called a \emph{complete set of representatives} if the equivalence classes are $[a_i], i \in I$ with no repetitions.

  You find such a subset by choosing from every equiv class one element.Considering our examples:
  \begin{itemize}
    \item For \cref{example:equiv1}, $S_n = X_1 \sqcup \dots X_n$, $X_i = \{\sigma : \sigma(1) = i\}$. We define \[\sigma_i (j) = \begin{cases}
      i & j = 1\\
      1 & j = i\\
      j & \text{otherwise} 
    \end{cases} = [\sigma_i]\] (switch $i,j$ and leave all others intact). $\{\sigma_1, \dots, \sigma_n\}$ are a complete set of representatives.
    \item For \cref{example:equiv2} (even/odd in $\mathbb{Z}$), a complete set of reps could be $\{0,1\}$, ie $\mathbb{Z} = [0] \sqcup [1]$.
\end{itemize}
\end{definition}


\section{Number Systems}
\subsection{Complex Numbers}
\begin{definition}[Complex Numbers]
  $\mathbb{C} = \{a + bi : a, b \in \mathbb{R}\}$. Equivalently, we can consider complex numbers as the points $(a,b) \in \mathbb{R}^2$.\footnotemark

  Given some $z = a + bi$, we can write $\re{z} = a, \im{z} =b$.
\end{definition}
\footnotetext{We can define the function $f: \mathbb{C} \to \mathbb{R}^2, f(a+bi) = (a,b)$, a bijection.}

\begin{definition}[Algebra on Complex Numbers]
  Given $z_i = x_i + y_i i$, we define:
  \begin{itemize}
    \item \emph{Addition}: $z_1 + z_2 = (x_1+ x_2) + (y_1 + y_2)i$. This is associative and commutative.
    \item \emph{Multiplication}: $z_1 z_2 = (x_1x_2-y_1y_2)+(x_1y_2+x_2y_1)i$
    \item \emph{Inverse}: $z \neq 0$, $\frac{1}{z} := \frac{\overline{z}}{|z|^2}$, noting that $z\cdot\frac{1}{z} = z\cdot\frac{\overline{z}}{|z|^2} = 1$
  \end{itemize}
\end{definition}

\begin{definition}[Complex Conjugate]
  Given $z = a + bi$, the \emph{complex conjugate} of $z$ is $\overline{z} = a - bi$.
\end{definition}

\begin{lemma}
  The following hold for complex conjugates:\footnotemark

  \begin{enumerate}[label=(\alph*)]
    \item $\overline{\overline{z}} = z$.
    \item $\overline{z_1 + z_2} = \overline{z_1} + \overline{z_2}, \overline{z_1 \cdot z_2} = \overline{z_1} \cdot \overline{z_2}$.
    \item $\re{z} = \frac{z+\overline{z}}{2}, \im{z}i = \frac{z-\overline{z}}{2}$.
    \item Given $|z| = \sqrt{a^2+b^2}$, 
    \begin{enumerate}[label=(\roman*)]
      \item $|z|^2 = z \cdot \overline{z}$
      \item $|z_1 + z_2|\leq |z_1| + |z_2|$
      \item $|z_1\cdot z_2| = |z_1| \cdot |z_2|$
    \end{enumerate}
  \end{enumerate}
\end{lemma}

\footnotetext{(a), (b), and (c) are simply algebraic rearrangements of two complex numbers. (d.i) and (d.iii) follow from similar arguments, and finally (ii) is the triangle inequality restated in terms of complex numbers.}
\subsection{Fundamental Theorem of Algebra, Etc}
\begin{theorem}[Fundamental Theorem of Algebra]
  Any polynomial $a_n x^n + \cdots + a_1 x + a_0$ for $a_i \in \mathbb{C}, n > 0, a_n \neq 0$, has a root in $\mathbb{C}$.
\end{theorem}

\begin{example}[Roots of Unity]
  Let $n\geq 1, n \in \mathbb{Z}$. $x^n = 1$ has $n$ solutions in $\mathbb{C}$, called the roots of unity of order $n$. They are given as $(1, \frac{2\pi k}{n}), k = 0, 1,2, \dots, n-1$ in polar notation.
\end{example}
\newpage
\begin{theorem}\label{thm:complexpolynomial}
  Let $f(x) = a_n x^n + \cdots + a_1 x + a_0$ be a complex polynomial of degree $n$. Then, there are complex numbers $z_1, \dots. z_n$ s.t. \[f(x) = a_n \prod_{i=1}^n (x-z_i) \qquad{(i)}\] each (ii) $f(z_j) = 0 \forall j=1,\dots,n$, and (iii) $f(\lambda) = 0 \implies \lambda = z_j$ for some $j$.\footnotemark
\end{theorem}

\footnotetext{
Proof sketch: we prove by induction. First, we prove the base case of polynomials of $\deg = 1$, then we assume it holds for $\deg \leq n$. We then prove a separate lemma (also by induction) that allows us to rewrite our polynomial as the product of some $(x - \lambda)$ factor, another polynomial, and some residual. We then rewrite our original polynomial as the product of some linear term and another polynomial, plus some residual, then show that this residual is 0, and thus show that our polynomial of degree $n+1$ is simply the product of some linear term and a polynomial of degree $n$, the inductive assumption, and thus the general statement is true.

The "sub"-claims follow naturally.
}

\begin{proof}[Proof (by induction)]
  If $n=1$, $f(x) = a_1 x + a_0 = a_1 \left(x - \frac{-a_0}{a_1}\right) = a_1 (x-z_1).$ Clearly, $f(z_1) = 0$.
  
  % If $0 = f(\lambda) = a_1(\lambda - z_1)$

  Assume that true for polynomials of degree $\leq n$ and prove for $n+1$; let $f$ be a polynomial of degree $n+1$, $f(x) = a_{n+1} + x^{n+1} + \cdots$. Let $z_{n+1}$ be a root of $f: f(z_{n+1}) = 0$. Such exists by the Fund'l Thm. We introduce the following lemma:
  \begin{lemma}
    Let $g$ be a polynomial with complex coefficients. Let $\lambda \in \mathbb{C}$; then we can write $g(x) = (x-\lambda)h(x) + r, r \in \mathbb{C}, h$ a polynomial with complex coefficients as well.
  \end{lemma}
  \begin{proof}[Proof of Sub-Lemma]
    By induction; we can write $g(x) = a_n x^n + \cdots a_1 x + a_0$. If $\deg(g) = 0$, then $g = a_0 \implies h(x) = 0, a_0 = r$.

    Assume this is true for degrees $\leq n$,and that $g$ has degree $\leq n + 1$. $$g(x) = (x - \lambda)a_{n+1}x^n + b(x),$$ where $b(x) = g(x) - (x-\lambda)a_{n+1}x^n = a_n' x^n + a_{n-1}' x^{n-1} + \cdots,$ for some $a_n', \dots, a_0' \in \mathbb{C}$. We can apply induction to $b(x)$ (that has $\deg \leq n$); $b(x) = (x-\lambda)h_1(x)+r,$ so $$g(x) = (x-\lambda)\underbrace{(a_{n+1}x^n+h_1(x))}_{h(x)}+r,$$ as desired.
  \end{proof}

  % we claim that $s_1, s_2 \in \mathbb{C}$ and $s_1\cdot s_2 = 0$, either $s_1=0$ or $s_2 = 0$. We have that $|s_1|\cdot|s_2| = |s_1\cdot s_2| = 0$, but $|s_1|, |s_2|$ real, so $|s_1|=|s_2| = 0$. Say $|s_1| = 0$; we can say $s_1 = x+y i$, then $|s_1|^2 = 0 =x^2 + y^2 \implies x = y = 0$.

  Now, we write our $f(x)$ as \[f(x) = (x-z_{n+1})h(x) + r, \] using the lemma. Then, \begin{align*}
    0 &= f(z_{n+1}) = (z_{n+1}-z_{n+1})h(z_{n+1}) + r\\
    &= 0 + r + 0 \implies r = 0,
  \end{align*}
  so \[f(x) = (x-z_{n+1})h(x).\] Comparing the highest terms: \begin{align*}
    a_{n+1}x^{n+1} + \cdots &= (x-z_{n+1})(*x^n + \dots)\\
    &\implies \text{ leading coefficient of } h(x) \text{ also } a_{n+1}.
  \end{align*}
  By induction, 
  \begin{align*}
    h(x) &= \underbrace{a_{n+1}}_{\text{lead coef of } h} \cdot \prod_{i=1}^{n}(x-z_i)\\
    &\implies f(x) = a_{n+1} \prod_{i=1}^{n+1} (x-z_i) \qquad (i)\text{ holds}
  \end{align*}

  Further:

  \begin{itemize}
    \item (ii): $f(z_j) = a_{n+1} \prod_{i=1}^{n+1} (z_j - z_i) = 0$ when $i =j$.

    \item (iii): if $f(\lambda) = 0$, then $a_{n+1} \prod_{i=1}^{n+1}(\lambda - z_i) = 0$. But if a product of two complex numbers is 0, then one of them is 0. $a_{n+1} \neq 0$, so some $\lambda - z_i = 0$, ie $\lambda = z_i$ for some $i$\footnotemark
  \end{itemize}
\end{proof}

\footnotetext{
This claim relies on the claim that $s_1 \cdot s_2 = 0 \iff s_1$ or $s_2 = 0$ for $s_1, s_2 \in \mathbb{C}$. This is fairly straightforward to prove, and can be extended to any number of complex numbers, ie $\prod_{i=1}^n s_i = 0 \iff \text{ some } s_i = 0$
}
\begin{definition}[Complex Exponential]
  The complex exponential, $e^z = 1 + \frac{z}{1} + \frac{z^2}{2!} + \dots$ can be Taylor expanded and we have that \[e^{i \theta} = \cos \theta + i \sin \theta.\]
\end{definition}

\begin{example}
  If $z = e^{x+yi} = e^x \cdot e^{yi} = e^x (\cos y + i \sin y)$, then $z = (e^x, y)$ in polars.

  We can apply this idea to prove some trigonometric formulas. Consider $e^{2i \theta}$; \begin{align*}
      e^{2i \theta} &= (\cos \theta + i \sin \theta)^2 = \underbrace{\cos^2 \theta - \sin^2 \theta}_{\text{Re}} + \underbrace{2 \sin \theta \cos \theta }_{\text{Im}}i\\
      e^{2i \theta} &= \underbrace{\cos(2 \theta)}_{\text{Re}} + i \underbrace{\sin (2 \theta)}_{\text{Im}}\\
      &\implies \cos(2 \theta) = \cos^2 \theta - \sin^2 \theta\\
      &\implies \sin(2 \theta) = 2 \sin \theta \cos \theta
    \end{align*}
\end{example}



\section{Rings}

\subsection{Definitions}

\begin{definition}[Ring]
  A ring R is a set with two operations\footnotemark
  \begin{itemize}
    \item \emph{Addition:} $R \times R \overset{+}{\longrightarrow} R, \quad (a,b) \mapsto a+b$
    \item \emph{Multiplication:} $R \times R \overset{\cdot}{\longrightarrow} R, \quad (a,b) \mapsto a \cdot b$
  \end{itemize}

  The following hold:
  \begin{enumerate}
    \item ($+$ is commutative) $a + b = b+a, \forall a,b \in R$.
    \item ($+$ is associative) $a + (b+c) = (a+b) +c, \forall a,b,c \in R$.
    \item (0) $\exists$ a zero element, 0, s.t. $0 + a = a + 0 = a, \forall a \in R$.
    \item (negative) $\forall a \in R, \exists b \in R$ s.t $a+b = 0$.
    \item ($\cdot$ associative) $a(bc) = (ab)c, \forall a,b,c \in R$.
    \item (1, multiplicative identity) $\exists 1 \in R$ s.t. $1 \cdot a = a \cdot 1 = a, \forall a \in R$.\footnotemark
    \item (distributive) $\forall a,b,c \in R$, $a(b+c) = ab + ac$
  \end{enumerate}

  $\mathbb{Z}, \mathbb{Q}, \mathbb{R}, \mathbb{C}, \mathbb{R}[i] := \{a + b_i: a,b \in \mathbb{Z}\}, M_2(\mathbb{Z}) := \{\begin{matrix}
  a & b\\
  c & d
  \end{matrix} : a,b,c,d \in \mathbb{Z}\}, \dots$ are all examples of rings.

\end{definition}
\footnotetext{Though not always explicitly stated, it is often specified that rings are \textit{closed} under addition/multiplication; $a,b \in R \implies a+b \text{ and } a \cdot b\in R$.}
\footnotetext{Some texts (Hungerford) do not require the multiplicative identity to exist in a ring; those with this property are called "rings with identity". In general, these are all relatively arbitrary conventions - they are defined as such to make other operations/observations clearer; they are not steadfast, natural definitions.}


\begin{remark}
  We do not require multiplication to be commutative; if it is, we call $R$ a \textbf{commutative ring} (eg $M_2(\mathbb{Z}), M_2(\mathbb{R})$ are not commutative).

  We also do not require inverse for multiplication (eg $2$ doesn't have an inverse in $\mathbb{Z}$).
\end{remark}

\begin{definition}[Field]
  A \emph{commutative}, non-zero, ring $R$  s.t. $\forall x \in R$ and $x \neq 0$ ($\iff 1 \neq 0 $ in $R$, ie $R$ is not a zero ring), $\exists y \in R$ s.t. $xy=yx=1$ is a \emph{field}.

  Fields include $\mathbb{Q}, \mathbb{R}, \mathbb{C}, \mathbb{Q}[i]$
\end{definition}

\begin{definition}[Zero Ring]
  $\{0\}$ with $0 + 0 = 0, 0 \cdot 0 = 0$, where $1 = 0$ (identity element is 0). 
\end{definition}

\begin{example}
  Show that $\mathbb{Q}[i]$ is a field.

  If $x \in \mathbb{Q}[i], x = a + b i \neq 0$ then \[\frac{1}{a+bi} = \frac{a-bi}{(a+bi)(a-bi)} = \underbrace{\frac{a}{a^2+b^2}}_{\in \mathbb{Q}} - \underbrace{\frac{b}{a^2+b^2}}_{\in \mathbb{Q}}i \in \mathbb{Q}[i],\] and thus $\mathbb{Q}[i]$ has multiplicative inverses in $\mathbb{Q}[i]$.
\end{example}

\begin{corollary}
  Note the following consequences of the above axioms:
  \begin{enumerate}
    \item $0$ is unique; if $x \in R$ has the property that $x + a = a+x = a \forall a \in R$, then $x = 0$.
    \item $1$ is unique; if $x \in R$ has the property that $x\cdot a = a \cdot x = a \forall a \in R$, then $x = 1$.
    \item The element $b$ s.t. $a+b = b+a = 0$ is uniquely determined by $a$; if $x \in R$ and $x + a = a+x = 0$, then $x = b$. We denote such $b$ as $-a$, ie \[-a + a = a+(-a) = a-a = 0.\]
    \item $-(-a)=a$.
    \item $-(x+y)=-x-y$.
    \item $x\cdot 0 = 0 \cdot x = 0 \forall x \in R$.
   \end{enumerate}
\end{corollary}

\begin{definition}[Subring]
  Let $R$ be a ring. A subset $S \subseteq R$ is a \emph{subring} if \begin{enumerate}
    \item $0,1 \in S$.
    \item $x,y \in S \implies x + y, -x, x \cdot y \in S$.
  \end{enumerate}
  Then, $S$ is a ring itself.

  $\mathbb{Z} \subseteq \mathbb{Q} \subseteq \mathbb{R} \subseteq \mathbb{C}$ are subrings; $\mathbb{Z} \subseteq \mathbb{Z}[i] \subseteq \mathbb{Q}[i] \subseteq \mathbb{C}$ are subrings; $M_2 (\mathbb{Z}) \subseteq M_2(\mathbb{R})$ are subrings.
\end{definition}

\newpage
\part{Arithmetic in the Integers}
\begin{displayquote}
Math $\equiv$ Poetry 
\end{displayquote}

\section{Division}
\subsection{With Residue}
\begin{theorem}
  Let $a,b \in \mathbb{Z}$ with $b\neq 0$. There exist unique integers $q$ (quotient) and $r$ s.t.\[a = q \cdot b + r, 0 \leq r < |b|.\]
\end{theorem}

\begin{proof}
  Assume $b>0$ (similar proof applies for $b < 0$). Consider the set $S = \{a - bx: x\in \mathbb{Z}, a - bx \geq 0\}.$ Note that $S \neq \varnothing$. If $a \geq 0$, take $x = 0$. If $a < 0$, take $x = a$ to get $a-bx=a-ba=a(1-b) \geq 0$.\\
  Thus, $S$ has a minimal element; let $r = \min(S)$. Because $r \in S, r \geq 0$, and \[r = a-bq \text{ some } q \in \mathbb{Z} \implies a= bq - r.\] Here, we claim $r < b$. If $r \geq b$, then $0 \leq r - b = a - b(q+1) \in S$, contradicting the minimality of $r$. Thus, $0 \leq r < b$.\\
  We wish to show that $q, r$ are unique, meaning that if $a = bq' + r', q' \in \mathbb{Z}, 0 \leq r < b \implies q = q', r=r'$.\\
  If $q = q'$, then $r = a -b q = a - bq' = r' \checkmark$.\\
  Otherwise, wlog, say $q > q'$. We then have \begin{align*}
    0 &= a - a = (bq +r) - (bq' + r')\\
    &= b(q-q') + (r-r')\\
    &\implies r' = r + b(q-q') \geq b,\,\bot (0 \leq r' < |b|)\\
  \end{align*}
\end{proof}

\subsection{Without Residue}

\begin{definition}
  Let $a,b \in \mathbb{Z}$. We say $a$ divides $b$, $a|b$ if $b = a \cdot c,$ some $c \in \mathbb{Z}$ (If $a \neq 0$, this is the case $\iff$ the residue of dividing $b$ by $a$ is 0).
\end{definition}

\begin{lemma}[Properties of Division]\label{lemma:propertiesofdivison}
  \begin{enumerate}
    \item $0$ is divisible by any integer $a$
    \item $0$ only divides $0$
    \item $a|b \implies a|(-b)$
    \item $a|b$ and $a|d \implies a|(b\pm d)$
    \item $a|b \implies a|bd \forall d$
    \item $a|b$ and $b|a \implies a =\pm b$
  \end{enumerate}
\end{lemma}

\begin{proof}
  \begin{enumerate}
    \item $0 = a\cdot 0 \forall a \checkmark$
    \item $0 | b,$ then $b = 0 \cdot c$ some $c \implies b = 0\quad \checkmark$
    \item $b = ac \implies -b = a \cdot (-c) \quad\checkmark$
    \item $b = a\cdot c_1$, $d = a \cdot c_2$. $b \pm d = a(c_1 \pm c_2) \in \mathbb{Z} \quad\checkmark$
    \item $b = ac$, so $bd = a \cdot (cd) \quad\checkmark$
    \item $a | b \implies b = a \cdot c, b |a \implies a = b \cdot d$. If either $a = 0$ or $b = 0$, both are $0$, so $a = \pm b$. Assume $a \neq 0, b \neq 0$. Then, we have that $a = bd = acd \overset{a \neq 0}{\implies} cd = 1$. Either, $c = d = 1 \implies a = b$, or $c = d = -1 \implies a = -b$ \quad \checkmark
  \end{enumerate}
\end{proof}

\begin{example}
  Which integers could divide both $n$ and $n^3 + n + 1$?\\
  Suppose $d$ does. then $d | n$ and $d | (n^3 + n + 1)$, then $d | n^3 \implies d |(n^3 + n) \implies d | ((n^3 + n + 1) - (n^3 +n))$, and so $d|1$ so $d = \pm 1$.
\end{example}


\subsection{Greatest Common Divisor (gcd)}

\begin{definition}[GCD]
  Let $a,b$ be integers, not both $0$.  The $\gcd$ of $a,b$ denoted $\gcd(a,b)$ is the greatest positive number divided both $a$ and $b$.
\end{definition}

\begin{remark}
  Note that if both $a,b$ are not $0$, then $d = \gcd(a,b) \leq \min\{|a|,|b|\}$ because if $d | a$ then $a = d \cdot c \implies |a| = |d| \cdot |c| \implies |d| = d \leq |a|$.\\
  Similarly, $|d| \leq |b|$.
\end{remark}

\begin{theorem}\label{thm:gcdproperties}
  Let $a,b \in \mathbb{Z}$, not both $0$. Let $d = \gcd (a,b)$. Then,
  \begin{enumerate}
    \item $\exists u,v \in \mathbb{Z} \st d = ua + vb$;
    \item $d$ is the minimal positive integer of the form $ua + vb$, $u, v \in \mathbb{Z}$;
    \item every common divisor of $a,b$ divides $d$.
  \end{enumerate}
\end{theorem}

\begin{proof}
  Let $S = \{ma + nb : m,n \in \mathbb{Z}, ma + nb > 0\}$. $S \neq \varnothing$ because $a\cdot a + b \cdot b = a^2 +b^2 > 0$, so $a^2 + b^2 \in S$.\\
  Let $D = \min(S)$, so $D = ua + vb, u,v \in \mathbb{Z}$. We claim that this $D$ equals $d = \gcd(a,b)$.\\ We claim first that $D | a$. We can write \begin{align*}
    a &= D \cdot q + r, 0 \leq r < D,\\
    r &= a - Dq = a - (ua + vb)q\\
    &= a(1-uq) + b(-vq)\\
    &\implies r > 0 \implies r \in S, \text{ contradicts minimality of } D
  \end{align*}
  Thus, $D$ divides both $a$ and $b$, and so $D \leq d$ (any common divisor is leq gcd).\\
  Let $e$ be any common divisor of $a,b$. We have
  $$e | a \implies e |ua \quad \text{ and } \quad e|b ,\implies e|vb \implies e|(ua+vb)=D.$$ In particular, $d|D \implies d \leq D$. It follows that $D = d$.
\end{proof}

\begin{example}
  $\gcd(7611, 592) = 1$. \\
  One can write $1 = 195 \times 7611 - 2507 \times 592$. How do we know? Mathematica.
\end{example}

\subsection{Euclidean Algorithm}

\begin{remark}
  $\gcd(-a,b) = \gcd(a,b) =\gcd(a,-b) = \cdots$
\end{remark}
\begin{theorem}[Euclidean Algorithm]
  Let $a,b$ be positive integers $a\geq b$. \\If $b | a$, then $\gcd(a,b) = b$.\\Else, perform the following:
  \begin{align*}
    a &= b \cdot q_0 + r_0, \quad 0 < r_0<b\\
    b &= r_0\cdot q_1 + r_1, \quad 0 < r_1 < r_0\\
    r_0 &= r_1 \cdot q_2 + r_2\\
    \vdots & \qquad \vdots\\
    r_{t-2} &= r_{t-1}\cdot q_t+r_t, \quad 0 < r_t < r_{t-1}\\
    r_{t-1}&=r_t\cdot q_{t+1} + \underbrace{0}_{r_{t+1}}
  \end{align*}
  Because the residues are non-negative decreasing integers, the process must stop; there is a first $t\st r_{t+1}=0$. Then, $\gcd(a,b) = r_t$, the last non-zero residue.\footnotemark
\end{theorem}
\footnotetext{Sketch: we show the equivalence by proving that they each divide each other, and are thus equal by \cref{lemma:propertiesofdivison}. This is done by induction on the residuals dividing "each other", and working "backwards" essentially, then by induction on an arbitrary element dividing the residuals to show that it must then divide the gcd.}

\begin{proof}
  We first prove by induction that for all $0 \leq i \leq t+1$, $r_t $ divides both $r_{t-i}$ and $r_{t-i-1}$. ($\implies r_t|r_{-1}=b, r_t|r_{-2}=a$.)\\
  \begin{itemize}
    \item[(1)] $i =0$, then $r_t | r_t$ and $r_t|r_{t-1}$ (as $r_{t-1} = r_{t}\cdot q_{t+1}$)
    \item[(2)] Suppose $r_t | r_{t-i}$ and $r_{t} | r_{t-i-1}$ for some $0 \leq i < t+1$. We have that $$r_{t-i-2} = r_{t-i-1} \cdot q_{t-i} + r_{t-i}$$ We then have that $$r_t | (r_{t-i} + r_{t-i-1}q_{t-i}) = r_{t-i-2},$$ so $r_t | \underbrace{r_{t-i-1}}_{r_{t-(i+1)}}$ and $r_t | \underbrace{r_{t-i-2}}_{r_{t-(i+1)-1}}.$ Then, $r_t | \gcd(a,b).$
  \end{itemize}
  Next we show that if $e|a$ and $e|b$ then $r|r_t$ ($\implies \gcd(a,b)|r_t$, then we would have $r_t = \gcd(a,b)$). We prove by induction on $0 \leq i \leq t+1$ that $e | r_{i-2}$ and $e | r_{i-1}$.
  \begin{itemize}
    \item[(1)] $i = 0$, then $e|r_{-2} = a$ and $e|r_{-1} =b$, base case holds
    \item[(2)] Suppose $e|r_{i-2}$ and $e|r_{i-1}$ for some $i < t+1$. We have that $$r_{i-2} = r_{i-1}\cdot q_i + r_i, \quad e|(r_{i-2} - r_{i-1}\cdot q_i) = r_i.$$
    So, $$e|\underbrace{r_i}_{r_{(i+1)-2}} \quad \text{ and } \quad e|\underbrace{r_i}_{r_{(i+1)-1}}$$
  \end{itemize}
\end{proof}

\begin{remark}[Extended Euclidean Algorithm]
  After completing the algorithm, one can then "work backwards" to write any $d = \gcd(a,b)$ as $d = ua + vb$.\\
  Start by writing $d = r_{t-2} - r_{t-1}\cdot q_t$; then, substitute in preceding residuals, simplifying along the way (but making sure to leave the \emph{quotients} from each substitution, as these are what you will substitute in the next step), and continue until you have the desired form. Consider the following example:
\end{remark}

\begin{example}
  $a = 48, b = 27, d = \gcd{48,27}=?$
  \begin{align*}
    48 &= 27 \cdot 1 + 21\\
    27 &= 21 \cdot 1 + 6\\
    21 &= 6 \cdot 3 + 3\\
    6 &= 3 \cdot 2 + 0\\
    &\implies\gcd(48,27)=3\\
    &\implies 3 = 21 - 6 \cdot 3\\
     &= 21 - (27-21)3 \\
     &= 21\cdot 4 - 27\cdot 3\\
     &= (48-27)\cdot 4 - 27\cdot 3\\
     &= 48 \cdot 4 - 7 \cdot 27
  \end{align*}
\end{example}

\subsection{Primes}

\begin{definition}[Prime]
  An integer $n \neq 0, 1, -1$ is called prime if its only divisors are $\pm 1, \pm n$.\\
  A positive integer $n$ is prime iff its only positive divisors are $1, n$.
\end{definition}

\begin{remark}
  The goal of this section is to prove \cref{thm:fta}, of unique prime factorization; we then extend it to the rationals. We introduce a number of lemmas/auxiliary results regarding primes to build up to the proof.
\end{remark}

\begin{lemma}\label{lemma:primefactorization}
 Every natural number $n > 1$ is a product of prime numbers.
\end{lemma}

\begin{proof}
  We prove by induction.\\
  Base case; $n = 2$, $2$ is prime, done.\\
  Suppose it is true for all integers $1 < r \leq n$; we will prove for $n+1$.\footnotemark
  \begin{itemize}
    \item If $n+1$ is prime, we are done.
    \item Else, $n+1$ has a non-trivial factorization, $n + 1 = r \cdot s$, where $1 < r \leq n, 1 < s \leq n$. By induction, there exists primes $p_i, q_i$ such that $r = p_1 \cdots p_a$ and $s = q_1 \cdots q_b$. We can then write $$n + 1 = r \cdot s = p_1 \cdots p_a q_1 \cdots q_b,$$ a product of primes, and so we are done.
  \end{itemize}
\end{proof}
\footnotetext{Complete induction...}

\begin{definition}[Empty Product]
  1; when we say $n = p_1 \cdots p_a, 0 \leq a$, a product of primes, a = 0, empty product, means $n = 1$.
\end{definition}

\begin{corollary}
  Any non-zero integer $n$ is of the form $$\epsilon \cdot p_1 \cdots p_a, \quad \epsilon \in \{\pm 1\}, $$ where $p_i$ are primes numbers, $a \geq 0$.
\end{corollary}

\begin{proof}
  If $n > 1$, this is the \cref{lemma:primefactorization} where $\epsilon = 1$. If $n < -1$, the by \cref{lemma:primefactorization}, $$-n = p_1 \cdots -p_n$$ so $n = -1 p_1 \cdots p_a = - p_1 \cdots p_a$.
\end{proof}

\begin{theorem}[Sieve of Eratosthenes]
  Let $n > 1$ be an integer. If $n$ is not prime, then $n$ is divisible by some prime $1 < p \leq \sqrt{n}$.
\end{theorem}

\begin{proof}[Sketch Proof]
  $n = p_1 \cdots p_a$. $n$ not prime, $a \geq 2$. If each $p_i > \sqrt{n}$, then $p_1 p_2 \cdots p_a < \sqrt{n}\cdot \sqrt{n} = n,\bot$
\end{proof}
  
\begin{lemma}\label{lemma:primediv}
  Let $p>1$ be an integer. The following are equivalent:
  \begin{enumerate}
    \item $p$ is prime
    \item If $p | ab$, product of two nonzero integers, then $p|a$ or $p|b$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  Assume 2., suppose $p = st \in \mathbb{Z}$. wlog, $s,t > 0$ (else replace $s$ by $-s$, $t$ by $-t$). $p|st$, so by 2., say $p|s$ , wlog. We can write $s = p \times w$, then $p = s\cdot t = p\cdot w \cdot t$, which are all positive integers. It must be that $w = t = 1$, and thus $s = p$. Therefore, $p$ has no non-trivial factorizations and is thus prime.\\
  Assume now that 1. holds; $p | ab$. If $p|a$, we are done. 
  \\Suppose $p \cancel{|} a$. Then, $\gcd(p,a) = 1$ (since only divisors of $p$ are 1, $p$, so $\gcd$ could only be $1,  p$, but if $\gcd = p$ then $p|a$ which is not the case). From a property of gcd's, we can write $1 = up + va$ for some $u,v \in \mathbb{Z}$. Multiplying this by $b$, we have $b = upb + vab$.\\
  We have \begin{align*}
    p|ab &\implies p |vab\\
    p|p &\implies p |upb\\
    &\implies p | (upb + vab) \text{, so } p |b
  \end{align*}
\end{proof}

\begin{corollary}
  Let $p$ be prime. Suppose $p | a_1 a_2 a_3 \cdots a_m$ where $a_i \in \mathbb{Z}, m \geq 1$. Then, $p| a_i$ for some $i$
\end{corollary}

\begin{proof}
  By induction; we just showed the case $m = 2$. Suppose it is true for $m \geq 2$ and $p | a_1 a_2 \cdots a_{m+1}$; then, $p | \underbrace{(a_1 a_2\cdots a_m)}_{(i)}\cdot \underbrace{a_{m+1}}_{(ii)}$. Then, either $p | (i)$ or $p| (ii)$, so $p | a_{m+1}$ or $p | a_i, 1 \leq i \leq m$, as required.
\end{proof}

\begin{theorem}[Fundamental Theorem of Arithmetic]\label{thm:fta}
  Let $n \in \mathbb{Z}, n \neq 0$. There exists $\epsilon \in \{\pm 1\}$ and prime numbers $p_1, \cdots, p_a, a \geq 0$ such that $n = \epsilon \cdot p_1 \cdots p_a$, \textbf{uniquely}.\footnotemark
\end{theorem}
\footnotetext{
Sketch: this shows only uniqueness, existence is proven by \cref{lemma:primefactorization}. Use induction; base case, $n=2$ trivial. Use complete induction, and proceed by contradiction (kind of). Assume that $n$ has two distinct prime factorizations. Then, break down by cases; $p_1 = q_1$ or not. If they are, then take some small $m$ covered by inductive assumption, set equal to $\frac{n}{p_1}$, meaning that if $p_1 = q_1$, the remaining $p_i = q_i$.\\ For inequality, show that $p_1 < q_1 \implies p_1 < p_1$ by showing that $p_1 | q_1 \cdots$, and thus $p_1 = q_i$ for some $i$, so $p_1 < q_1 \leq \cdots q_i =p_1$, and thus you have a contradiction.

}

\begin{proof}
  First, it is clear that the sign is unique, so wlog, we only consider positive $n$. We have already proved that $\exists$ such a factorization by \cref{lemma:primefactorization}; we now aim to show that this is unique. We proceed by induction.\\
  \textit{Base case:} $n = 1$; $p_i,q_j \geq 2$, only option is the empty product $a = b = 0$.\\
  \textit{Assumption:} say holds for integers $1 \leq m \leq n -1$, $n \geq 2$ (numbers smaller than $n$). We are given \[n = p_1 \cdots p_a = q_1 \dots q_b.\]
  \begin{itemize}
    \item Suppose $p_1 = q_1$. Then $m = \frac{n}{p_1} = p_2 \cdots p_a = q_2 \cdots q_b \implies a = b$ and $p_i = q_i$ for $2 \leq i \leq a$ (and also, $p_1 = q_1$) (covered by inductive hypothesis)
    \item Otherwise, $p_1 \neq q_1$, and wlog (symmetric) $p_1 < q_1$. We have $p_1 | n$ so $p_1 | q_1 \cdots q_b \overset{p \text{ prime}}{\implies} p_1 | q_i$ for some $1 \leq i \leq b$ (by \cref{lemma:primediv}, extended to the product of any number of numbers). As $p_i$ prime, $p_1 = q_i$, implying $p_1 < q_1 \leq q_2 \leq \cdots q_i = p_1$, a contradiction to the assumption that $p_1 < q_1$. Thus, $p_1 = q_1$.
  \end{itemize}

  Alternatively, we could write $n = \epsilon p_1^{a_1} \cdots p_s^{a_s}$ where $p_i$ are distinct prime numbers and $a_i > 0$ (ie, we are "collecting" the identical primes, and raising them to the power of how many times they appear) where $p_i$ and $a_i$ are unique.
\end{proof}

% !
\begin{theorem}[Version of FTA for Rationals]
  Let $q\neq 0$ be a rational number. Then, $\exists$ a unique sign $\epsilon \in \{\pm 1\}$, integer $s$, primes $p_1, \dots, p_a$ and exponents $a_i \in \mathbb{Z}, a_i \neq 0 \st$
  \[q = \epsilon \cdot p_1^{a_1} \cdots p_s^{a_s}\]
\end{theorem}
% TODO: sketch needed
\begin{proof}
  Write $q = \frac{m}{n}$, where $m,n \in \mathbb{Z}$. Then, we can write $m$ as \[m = \epsilon_m \cdot p_1^{b_1} \cdots p_s^{b_s};\qquad n = \epsilon_n \cdot p_1^{c_1}\cdots p_s^{c_s}\]
  \begin{remark}
    If we allow 0 as an exponents, we can write these such that the same primes appear in both $n$ and $m$.
  \end{remark}
  We can then write \[\frac{m}{n} = \frac{\epsilon_m}{\epsilon_n} p_1^{b_1-c_1}\cdots p_s^{b_s-c_s}.\] We can now omit the primes with $b_i - c_i = 0$ to get only non-zero exponentiated primes. We have thus shown existence\\
  To show uniqueness, we can disregard the sign as before.  Say $0 < q = p_1^{a_1}\cdots p_s^{a_s} = p_1^{a_1'}\cdots p_s^{a_s'}$. If these are equivalent representations, then letting $c_i = a_i - a_i'$, we get that $1 = p_1^{c_1} \cdots p_s^{c_s}$; thus, we aim to show that $c_1 = \cdots c_s = 0$. wlog, we can rearrange these $c$'s such that $c_1, \cdots , c_t < 0, c_{t+1} , \cdots, c_s \geq 0$. This implies that $p_1^{-c_1} \cdots p_t^{-c_t} = p_{t+1}^{c_{t+1}} \cdots p_s^{c_s}$. This is an equality on integers, and as given by FTA, this is only possible if $c_i = 0 \forall i$.
\end{proof}

\begin{proposition}
  $\sqrt{2} \notin \mathbb{Q}$
\end{proposition}
\begin{proof}
  Suppose it is. Then $\sqrt{2} = p_1^{a_1}\cdots p_s^{a_s}$, $a_i \neq 0, p_i$ distinct primes. Then, we have \[2 = (p_1^{a_1} \cdots p_s^{a_s})^2 = p_1^{2a_1}\cdots p_s^{2a_s}.\] But, $2 = 2^1$, and by uniqueness of factorization, we get a contradiction because $1  \neq 2a_{i}$ for any i.
\end{proof}

\begin{theorem}
  There exist infinitely many prime numbers.
\end{theorem}

\begin{proof}
  Suppose $p_1, \dots, p_n$ are distinct prime numbers. Then, there exists a prime number $p_{n+1}$ which is not one of these. Let $N = p_1 p_2 \cdots p_n +1 > 1$, so $\exists p|N$ where $p$ prime. If $p =$ on of $p_1 \dots p_n$, say some $p_i$; then, $p | N$ and $p | p_1 p_2 \cdots p_n \implies p | (N - p_1 \cdots p_n) \implies p | 1$, which is a contradiction.
\end{proof}

\begin{proposition}
  Let $a,b \neq 0, a,b \in \mathbb{Z}$. Then $a|b \iff a| \epsilon p_1^{a_1} \cdots p_m^{a_m}, a_1 > 0, p_i$ prime, $\epsilon \in \{\pm 1\}$ and $b = \mu p_1^{a_1'} \cdots p_m^{a_m'}q_1^{b_1}\cdots q_t^{b_t},a_i' \geq a_i, q_i$ primes, $b_i > 0$.
\end{proposition}

\begin{proof}
  If we can, then $\frac{b}{a} = \underbrace{\frac{\mu}{\epsilon} \cdot p_1^{a_1'-a_1}\cdots p_m^{a_m'-a_m}q_1^{b_1}\cdots q_t^{b_t}}_{:=c} \implies b = a \cdot c \implies a|b$.\\
  If $a|b$ so $b = a \cdot d$. We can write $a = \epsilon p_1^{a_1}\cdots p_m^{a_m}$, and $d = \epsilon' p_1^{r_1}\cdots p_m^{r_m}q_1^{b_1}\cdots q_t^{b_t}$, and let $b = (\epsilon \epsilon ')p_1^{a_1 + r_1} \cdots p_m^{a_m+r_m} q_1^{b_1}\cdots q_t^{b_t}$ (where $r_i > 0$), and let $a_i' = a_i+r_i \geq a_i$.
\end{proof}

\begin{corollary}
  Let $n = \epsilon p_1^{a_1}\cdots p_t^{a_t} \in \mathbb{Z}$, $\epsilon = \pm 1$, $p_i$ distinct primes, $a_i > 0$. Then the divisors of $n$ are precisely the integers \[\mu p_1^{c_1}\cdots p_t^{c_t}, \quad \mu = \pm 1, 0 \leq c_i \leq a_i.\]
\end{corollary}

\begin{remark}
  Let $a,b \in \mathbb{Z}\setminus \{0\}$; we write \[a = \epsilon p_1 ^{a_1} \cdots p_t^{a_t}, b = \mu p_1^{b_1}\cdots p_t^{b_t}.\] We have $d = \gcd(a,b) = p_1^{\min(a_1,b_1)}\cdots p_t^{\min(a_t,b_t)}$.\\
  \cref{thm:gcdproperties} also follows naturally from this manner of thinking, and can be proved accordingly.
\end{remark}

\begin{example}
  $90 = 2 \cdot 3^2 \cdot 5 \cdot 7^0; 210 = 2 \cdot 3 \cdot 5 \cdot 7$. $\gcd(90,210) = 2 \cdot 3 \cdot 5 \cdot 7^0 = 30\checkmark$.
\end{example}

\part{Congruences and Modular Arithmetic}

\section{Congruence Relations}
\subsection{Definitions}
\begin{definition}
  Fix $n \geq 1, n \in \mathbb{Z}$. We define a relation of $\mathbb{Z}$ by $x \sim y$ if $n | (x-y)$.
\end{definition}

\begin{example}
$n = 2$; $x \sim y$ if they have the same parity, ie both even or both odd.  
\end{example}

\begin{lemma}
  The above relation is an equivalence relation. We will denote the equivalence class of an integer $r$ by $\overline{r}$. Then, \[\overline{r} = \{\dots r - 2n, r - n, r , r+n, r + 2n, \dots\}.\]
  The set \[
  \{\overline{0}, \overline{1}, \cdots, \overline{n-1}\}  
  \]
is a complete set of representatives.
\end{lemma}

\begin{proof} We first show that the relation is an equivalence relation:\\
  \textbf{Reflexive: } $x - x = 0 \implies n | (x-x) \forall n$, so $x \sim x$.\\
  \textbf{Symmetric: } say $x \sim y \implies n | (x-y) \implies n | -(x-y) \implies n | (y - x) \implies y \sim x$.\\
  \textbf{Transitive: } say $x \sim y, y \sim z \implies n | (x-y), n |(y-z) \implies n | ((x-y) + (y-z)) \implies n | (x-z) \implies x \sim z$.\\
  Now, we show that the described set is a complete set of representatives, ie we aim to show \begin{enumerate}
    \item \textit{any $x \in \mathbb{Z}$ belongs to some $\overline{r}, 0 \leq r \leq n-1$.}


    Proof of 1: Given $x \in \mathbb{Z}$, we can write $x = q \cdot n + r, 0 \leq r \leq n - 1$, and $x - r = q \cdot n\implies n | (x-r)$, so $x \sim r$. Ie, $x \in \overline{r}$.
    \item \textit{if $0 \leq r \leq s \leq n - 1$ and $\overline{r} = \overline{s}$, then $r = s$ (no repetitions, ie "repeat representation").}
    

   Proof of 2: If $\overline{r} = \overline{s}$, then $r \in \overline{r}$ and $r \in \overline{s}$, so $r \sim s$. So, $n | (s-r)$; but $0 \leq s - r \leq n - 1 < n$, implying $s-r = 0 \implies s = r$ (since it must be a multiple of $n$, but less than $n$).
  \end{enumerate}
\end{proof}

\begin{example}
  For $n = 2$, we have two equivalence classes, $\overline{0} =\text{evens} = \{2x : x \in \mathbb{Z}\}, \overline{1} = \text{odds} = \{2x + 1s: x \in \mathbb{Z}\}$.\\
  For $n = 3$, we have three; $\overline{0} = \{3x : x \in \mathbb{Z}\}, \overline{1} = \{1 + 3x : x \in \mathbb{Z}\}, \overline{2} = \{2 + 3x : x \in \mathbb{Z}\}$.
\end{example}


\begin{definition}
  $x \sim y$, we say $x$ is congruent to $y \text{ modulo } n$, and write \[x \equiv y \mod n.\]
\end{definition}

\begin{definition}
  We use $\mathbb{Z}/ n \mathbb{Z}$ or $\mathbb{Z}_n$ to denote the collection of congruence classes $\mod n$, ie $\mathbb{Z}/ n \mathbb{Z} = \{\overline{0}, \overline{1}, \dots, \overline{n-1}\}$.
\end{definition}

\begin{theorem}\label{thm:zmodnzringfield}
  $\mathbb{Z}/ n \mathbb{Z}$ is a commutative ring with $n$ elements. It is a field iff $n$ is prime.\\
  We often denote $\mathbb{Z}/p \mathbb{Z}$ where $p$ prime as $\mathbb{F}_p$.
\end{theorem}
\begin{proof}
  We define $\overline{r} + \overline{s} = \overline{r + s}$, $\overline{r} \cdot \overline{s} = \overline{rs}$. This is well defined; meaning if we use other representatives $r', s'$, we'll get the same result. Ie, given $r \sim r', s \sim s'$, we need to show $\overline{r' + s'} = \overline{r+s}, \overline{r'\cdot s'} = \overline{r \cdot s}$, ie $n | ((r+s) - (r'+s')), n | (rs - r's')$.\\
  $(r+s) - (r'+s') = (r - r') + (s-s')$; both $r-r'$ and $s - s'$ are divisible by $n$, so we can write $rs - r's' = r(s-s') + s'(r-r')$; this whole thing is divisible by $n$. Now, we can verify the axioms:
  \begin{enumerate}
    \item $\overline{r} + \overline{s} = \overline{s} + \overline{r}; \overline{r} + \overline{s} = \overline{r+s} = \overline{s + r} = \overline{s} + \overline{r}$ \quad \textit{(commutativity of addition)}
    \item $\dots$
    \item $\overline{0}$ is the neutral element; $\overline{0} + \overline{r} = \overline{0 + r} = \overline{r}$ \quad \textit{(neutral addition element)}
    \item $\overline(r) + \overline{(-r)} = \overline{(-r)} + \overline{r} = \overline{0}$ \quad \textit{(inverse wrt addition)}
    \item $\dots$
    \item $\overline{1} \cdot \overline{r} = \overline{r}$
    \item $\dots$
    % TODO above
  \end{enumerate}

  We now aim to show that $\mathbb{Z} /n \mathbb{Z} \iff n \in \mathbb{P}$. Suppose $n$ composite, namely $n a \cdot b$, $1 < a < n, 1 < b < n$. Note that $\overline{a}, \overline{b} \neq \overline{0}$; but, $\overline{a}\cdot \overline{b} = \overline{a \cdot b} = \overline{n} = \overline{0}$. If $\mathbb{Z}\setminus n \mathbb{Z}$ is a field, then $\exists \overline{y} \st \overline{y} \cdot \overline a = \overline{1}$. We have $(\overline{y} \cdot \overline{a}) \cdot \overline{b} = \overline{1} \cdot \overline{b} = \overline{b}$, but $\overline{y}\cdot (\overline{a} \cdot \overline{b}) = \overline{y} \cdot \overline{0} = \overline{0}$, a contradiction.\\
  Suppose, now, $n \in \mathbb{P}$. To show $\mathbb{Z}/n \mathbb{Z}$ is a field; let $\overline{a}  \neq \overline{0} \in \mathbb{Z}/n \mathbb{Z}$, that is $n \cancel{|}a$. But $n$ is prime, so $\gcd(a,n) = 1$, so $\exists u,v \in \mathbb{Z}$ such that $1 = ua + vn$. But this means $$n|(1-ua) \implies ua \equiv 1 \mod n \implies \overline{u} \cdot \overline{a} = \overline{1} \in \mathbb{Z}/n \mathbb{Z},$$ and we have thus found a multiplicative inverse.
\end{proof}

\begin{example}
  $n = 2$; we have \begin{tabular}{c|cc}
    + & 0 & 1\\
    \hline
    0 & 0 & 1\\
    \hline
    1 & 1 & 0
  \end{tabular} and \begin{tabular}{c | cc}
    $\times$ & 0 & 1\\
    \hline
    0 & 0 & 0\\
    \hline
    1 & 0 & 1
  \end{tabular};
  $\overline{1} + \overline{1} = \overline{2} = \overline{0}$.
\end{example}
\begin{example}
  $n = 3$; we have \begin{tabular}{c|ccc}
    + & 0 & 1 & 2\\
    \hline
    0 & 0 & 0 & 0 \\
    \hline
    1 & 1 & 2 & 0\\
    \hline
    2 & 2 & 0 & 1
  \end{tabular}
  and \begin{tabular}{c|ccc}
    $\times$ & 0 & 1 & 2\\
    \hline
    0 & 0 & 0 & 0\\
    \hline
    1 & 0 & 1 & 2\\
    \hline
    2 & 0 & 2 & 1
  \end{tabular}; $\overline{2} + \overline{2} = \overline{4} = \overline{1}$.
\end{example}

\begin{lemma}
  Let $R$ be a commutative ring. If $R$ has zero divisors then $R$ is not a field.
\end{lemma}

\begin{proof}
  Let $x \neq 0$ be a zero divisor, and $y \neq 0 \st xy = 0$. If $R$ a field, then $\exists z \in R \st zx = 1$. But then, $z(xy) = z \cdot 0 = 0$, and $z(xy) = (zx)y = 1\cdot y = y$, hence $y$ must be 0, a contradiction.
\end{proof}
% TODO: add second proof?
\begin{definition}[Unit]
  An element $x$ in a ring $R$ is called a \emph{unit} if $\exists y \in R$ such that $xy = yx = 1$.
\end{definition}
\begin{example}
  If $R$ a field, then any nonzero $x \in R$ is a unit. If $R = \mathbb{Z}/6\mathbb{Z}$, then $2,3,4$ are not units, but $1$ and $5$ are units.
\end{example}
% TODO: review, this shits confusing
\begin{proposition}
  Take $n > 1$. An element $\overline{a} \in \mathbb{Z}/n\mathbb{Z}$ is a unit iff $\gcd(a,n) = 1$.
\end{proposition}

\begin{proof}
  Note: $\gcd (a,n)= 1$ depends only on the congruence class $\overline{a}$; $\gcd (a+kn, n) = \gcd(a,n)$. Suppose $\overline{a}$ is a unit, ie $\exists \overline{y} \in \mathbb{Z}/n\mathbb{Z} \st \overline{y} \cdot \overline{a} = \overline{1} \implies \overline{ya} = \overline{1} \implies ya - 1 = k \cdot n$, for some $k \in \mathbb{Z}$, ie $ya - kn = 1$. Thus, if $d | a$ and $d|n$, then $d|1 \implies d = \pm 1 \implies \gcd (a,n) = 1$. \\Conversely, suppose $\gcd (a,n) = 1$. Then, $\exists u,v \in \mathbb{Z} \st ua + vn = 1 \implies \overline{u} \cdot \overline{a} + \overline{v} \overline{n} = \overline{1}$. Now, $\overline{n} = \overline{0} \implies \overline{v} \cdot \overline{n} = \overline{0}$, so $\overline{u} \cdot \overline{a}= 1$, hence $\overline{a}$ is a unit.
\end{proof}

\begin{corollary}
  If $n$ is prime any $\overline{a} \neq \overline{0}$ is a unit. 
\end{corollary}

% TODO: finish catching up above


\subsection{Binomial Coefficients}

\begin{definition}[Binomial Coefficient]
  Let $m \geq n$ be non-negative integers. $m \choose n$ ($m$ choose $n$) ways to choose $m$ objects among $n$ objects, where order doesn't matter, where $m \choose{n}$$= \frac{m!}{n!(m-n)!}$.\\
  We also have that \[\begin{pmatrix}
    n\\
    l
  \end{pmatrix} + \begin{pmatrix}
    n\\
    l-1
  \end{pmatrix} = \begin{pmatrix}
    n+1\\
    l
  \end{pmatrix}\]
\end{definition}

\[
\begin{array}{rrrrrrr}
  & & & \begin{pmatrix}
    0\\0
  \end{pmatrix} & & & \\
  & & \begin{pmatrix}
    1\\
    0
  \end{pmatrix} & & \begin{pmatrix}
    1\\1
  \end{pmatrix} & \\
  & \begin{pmatrix}
    2\\0
  \end{pmatrix} && \begin{pmatrix}
    2 \\1
  \end{pmatrix} && \begin{pmatrix}
    2 \\ 2
  \end{pmatrix} & \\
  \begin{pmatrix}
    3 \\0
  \end{pmatrix} && \begin{pmatrix}
    3 \\1
  \end{pmatrix} & &
  \begin{pmatrix}
    3 \\2
  \end{pmatrix} & &
  \begin{pmatrix}
    3 \\3
  \end{pmatrix}
\end{array}
\]
\textit{Pascal's Triangle}
\begin{lemma}\label{lemma:binomialprime}
  Let $p \in \mathbb{P}$, and let $1 \leq n \leq p - 1$. Then, $$p | \begin{pmatrix}
    p\\n
  \end{pmatrix}$$.
\end{lemma}


\begin{proof}
  First note that if $1 \leq a \leq p -1, p \not|a!$. If $p | a! = 1\cdot 2 \cdot 3 \cdots a$, then $p | b$ where $b = \{1, 2, \dots a\}$. But we have that $1 \leq b \leq p$, so this is not possible.\\
  Now, we have $\begin{pmatrix}
    p\\
    n
  \end{pmatrix} = \frac{p!}{n!(p-n)!} = d \in \mathbb{Z} \implies p! = d \cdot n!(p-n)!$. As $p | p!$ and $p\not|n!$ nor $(p-n)!$, (as shown above) since $n \leq p -1, p-n \leq - 1$, so, since $p$ prime, $p | d$.
\end{proof}



\subsection{Solving Equations in \texorpdfstring{$\mathbb{Z}/n\mathbb{Z}$}{Z/nZ}}

\begin{definition}
  
\end{definition}
\subsubsection{Linear Equations}
% TODO: should be before
\newpage
\subsection{Fermat's Little Theorem}
\begin{theorem}[Fermat's Little Theorem]\label{thm:fermatslittle}
  Let $p$  be a prime number. Let $a\not\equiv 0\mod p$ then \[a^{p-1}\equiv 1 \mod p.\]
\end{theorem}

\begin{remark}
  This implies that, for every $a$, $a^p \equiv a \mod p$. Conversely, If $a \not\equiv 0 \mod p$, then $a^p \equiv a \mod p \implies a^{p-1} \equiv 1 \mod p$ by multiplying both sides with the congruence class $b \st ba \equiv 1 \mod p$.
\end{remark}

\begin{lemma}\label{lemma:fermatslittlelemma}
  Let $R$ be a commutative ring and $x,y \in R$. Interpret $\begin{pmatrix}
    n\\
    i
  \end{pmatrix}$ as adding $1$ to itself $\begin{pmatrix}
    n\\
    i
  \end{pmatrix}$ times. Then, the binomial formula holds in $R$, ie\[(x+y)^{n} = \sum_{i=0}^{n} \begin{pmatrix}
    n\\
    i
  \end{pmatrix}x^{i}y^{n-i}.\]
  Ie, $\begin{pmatrix}
    n\\
    j
  \end{pmatrix}$ means $1_R + \cdots + 1_R, \begin{pmatrix}
    n\\j
  \end{pmatrix}$ times.
\end{lemma}

\begin{proof}(Of \cref{lemma:fermatslittlelemma})
  We proceed by induction. Case $n= 1$, clear; $(x+y)^1 = x^1 + y^1 \checkmark$.\\
  Assume it holds for $n$. We write \begin{align*}
    (x+y)^{n+1} = (x+y)^{n}(x+y) &= \underbrace{\left(\sum_{j=0}^n \begin{pmatrix}
      n\\j
    \end{pmatrix}x^{n-j}y^j\right)}_{\text{assumption}}\cdot(x+y)\\
    &= \sum_{l=0}^{n+1} c_l x^{n+1 - l} \cdot y^l
  \end{align*}
  where $c_l = \underbrace{\begin{pmatrix}
    n\\l
  \end{pmatrix}}_{\text{from } \begin{pmatrix}
  n\\l
  \end{pmatrix}x^{n-l}y^lx} + \underbrace{\begin{pmatrix}
    n\\l-1
  \end{pmatrix}}_{\text{from } \begin{pmatrix}
  n\\l-1
  \end{pmatrix}x^{n-(l-1)y^{l-1}y}} = \begin{pmatrix}
    n+1\\l
  \end{pmatrix}$, hence $(x+y)^{n+1} = \sum_{l=0}^{n+1} \begin{pmatrix}
    n+1\\l
  \end{pmatrix} x^{n+1-l}y^{l}$.
\end{proof}

\begin{proof}(Of \nameref{thm:fermatslittle})
  We aim to show that $a^p \equiv a \mod p$ for any $a$. It is sufficient to show that it holds for $1 \leq a \leq p - 1$.\\
  We prove by induction on $1 \leq a \leq p -1$. $a = 1 \implies 1^p \equiv 1 \mod p$.\\ Suppose it holds for $1 \leq a\leq p -2$, and prove for $a+1$. Then, by \cref{lemma:fermatslittlelemma}, \begin{align}
    (a+1)^{p} &= \sum_{i=0}^{p} \begin{pmatrix}
      p\\
      i
    \end{pmatrix}a^{i}\\
    &\equiv a^p + \begin{pmatrix}
      p\\1
    \end{pmatrix}a^{p-1} + \begin{pmatrix}
      p\\2
    \end{pmatrix}a^{p-2} + \cdots + \begin{pmatrix}
      p\\p-1
    \end{pmatrix}a + 1\\
    &\equiv 1 + a^p \quad \text{(by \cref{lemma:binomialprime})}\\
    &\equiv 1 + a\quad \text{by induction hypothesis}
  \end{align}
  Since $1 + a \not\equiv 0 \mod p$, it has an inverse in $y \in \mathbb{F}_p, y(1+a) \equiv 1$. Then, $y(1+a)^p\equiv y(1+a) \equiv 1$. Also, $y(1+a)^p = y(1+a)(1+a)^{p-1} \equiv (1+a)^{p-1}$, hence $(1+a)^{p-1} \equiv 1$.
\end{proof}


\begin{example}[Application of \nameref{thm:fermatslittle}]
  Calculate $2^{2023} \cdot 3^9 \mod 7$. Divide $2023$ by $6 = 7-1 = p - 1$ with residue. $2023 = 6 \cdot 337 + 1$, and $9 = 1 \cdot 6 + 3$.\\
  $2^{2023} \cdot 3^9 = 2(2^{6})^{337}\cdot 3^6 \cdot 3^3$. By FLT, this is equivalent to $2(1)^{337}\cdot 1 \cdot 3^3 \equiv 2 \cdot 27 \equiv 54 \equiv 5 \mod 7$.
\end{example}


\part{Arithmetic of Polynomials}

\section{Analog to Integers}

\subsection{Definitions}

\begin{definition}[Polynomial Ring]
  Let $\mathbb{F}$ be a field, and let $\mathbb{F}[x]$ be the ring of polynomials with coefficients in $\mathbb{F}$, ie \[\mathbb{F}[x] = \{a_n x^{n} + \cdots a_1 x + a_0 : a_i \in \mathbb{F}\}.\]
  Operations of addition, multiplication are defined as is familiar.
\end{definition}

\begin{example}
  $\mathbb{F} = \mathbb{Z}/3 \mathbb{Z}$. We have \begin{align*}
    (x^2 + x + 1)(2x + 1) + 2x^2 + 5 \equiv 2x^3 + (\cancelto{0}{1+2})x^2 + \cancelto{0}{(1+2)}x + 1 + 2x^2 + 6\\
    \equiv 2x^3 + 2x^2 + \cancel{6} \mod 3
  \end{align*}
\end{example}

\begin{definition}[$\deg$]
  If $f = a_n x^n + \cdots a_1 x + a_0$ has $a_n \neq 0$, we say $\deg f = n$, unless $f = 0$, where $\deg f$ undefined.\\
  If $f,g$ not zero, then $\deg (f \cdot g) = \deg (f) + \deg (g)$; thus, if $f,g$ are not zero, $f \cdot g \neq 0$. If $f \cdot g = 0$, we must have either that $f = 0$ or $g = 0$, or both. Thus, this is a commutative ring with no zero divisors. 
\end{definition}

\begin{theorem}[Division with Residue]
  Let $f,g \in \mathbb{F}[x]$, $g \neq 0$. Then, $\exists !$ polynomials $g, r \in \mathbb{F}[x]$ s.t. $f = q \cdot g + r$, where either $r = 0$ or $\deg (r) < \deg (g)$; furthermore, $q,r$ are unique.
\end{theorem}

\begin{proof}
  If $f = 0$, then take $q = 0, r = 0$ (no other choice). Take $f \neq 0$ wlog. We first prove \textit{existence} by induction on $\deg f$. 
  \begin{itemize}
    \item \textit{Base:} $\deg f = 0$: If $\deg g > 0$, let $q = 0$, $r =f$, hence $f = 0 \cdot g + f$. Otherwise, if $\deg g = 0$, then $g$ is a constant, then $f = (f g^{-1}) \cdot g + 0$.
    \item \textit{Assumption:} suppose true for all polynomials $h \in \mathbb{F}[x]$ such that $\deg h \leq n$ and $\deg f = n+1$.  Say $f = a_{n+1}x^{n+1} + $ l.o.t.\footnotemark, and $g = b_{m} x^{m} + $ l.o.t., where $b_m \neq 0$. 
    \begin{itemize}
      \item If $n+1 < m$, then $f = 0 \cdot g + f$, $\deg f < \deg g$.
      \item If $n + 1 \geq m$, then $f(x) = \underbrace{a_{n+1} b_{m}^{-1} x^{n+1-m} g}_{=a_{n+1}x^{n+1} + \text{ l.o.t}} + h(x)$, where $h$ is essentially the "difference" between the expression. Note that $\deg h \leq n$; hence, by induction $h(x) = \tilde{q}(x)\cdot g(x) + r(x)$, where either $r(x) = 0$ or $\deg r < \deg g$. This implies that $$f(x) = \underbrace{(a_{n+1} b_m^{-1} x^{n+1-m} + \tilde{q}(x))}_{q(x)} g(x) + r(x).$$
    \end{itemize}
  \end{itemize}
  Thus, the proof holds for all $\deg f$. We know show uniqueness. Suppose $f = q_1 g + r_1 = q_2 g + r_2$, where $r_i = 0$ or $\deg r_i < \deg g$. Consider \[(q_1 - q_2)g = r_2 - r_1.\] If RHS $\neq 0$, then the LHS $\neq 0$, hence $q_1 - q_2 \neq 0$. Since $g \neq 0$, then $\deg( \text{LHS}) = \deg (q_1 - q_2) + \deg g \geq \deg g$. But $\deg \text{RHS} \leq \max (\deg r_1, \deg r_2) < \deg g$, and we have a contradiction. Hence, RHS = $0 \implies $ LHS = 0, hence $q_1 - q_2 = 0$, so $r_1 = r_2$, $q_1 = q_2$, and the polynomial is thus unique.
\end{proof}
\footnotetext{Lower order terms}


\begin{definition}[Divisibility]
  We say $g | f$ if $r = 0$; namely,
  \[f = q \cdot g \text{ for some } q \in \mathbb{F}[x].\] As before, $g | f \implies g | hf$ for any $h \in \mathbb{F}[x]$; $g | f_1, g|f_2 \implies g | (f_1 \pm f_2)$; etc. Many of the other consequences of divisibility in integers follow similarly.
\end{definition}


\subsection{GCD}
\begin{definition}[GCD of Polynomials]
  Let $f,g \in \mathbb{F}[x]$ not both 0. The greatest common divisor of $f,g$ denoted $\gcd (f,g)$ is a \emph{monic} polynomial of largest degree dividing both $f$ and $g$.
\end{definition}

\begin{definition}[Monic]
  $f = a_n x^{n} + \cdots + a_0$, $a_n \neq 0$ is \emph{monic} if $a_n = 1$ (leading term is one).
\end{definition}

\begin{theorem}[GCD]
  $\gcd (f,g) $ exists and is unique. Furthermore, of the nonzero monic polynomials of the form $$u(x) f(x) + v(x) g(x),$$ it has the minimal degree. Any common example of $f,g$ divides the gcd.
\end{theorem}

\begin{proof}
  \begin{itemize}
    \item \textit{Existence: } Let $S := \{a(x) : a(x) \text{ monic, nonzero}; a(x) = u(x) f(x) + v(x) g(x).\}$. $S \neq \varnothing$; if $f \neq 0$, rather $f = a_n x^{n} + $ l.o.t., then $a(x) = a_{n}^{-2} f(x)\cdot f(x) + 0 \cdot g(x) \in S$ (if $f = 0$, use $g$ by same argument). Choose some $h(x) \in S$ have the minimal positive degree.
  
    \item \textit{Unique: } suppose $h_1(x) \in S$ and $\deg h = \deg h_1 = d$, $h = x^{d} + \text{lot} = uf + vg$, $h_1 = x^{d} + \text{log} = u_1f + v_1g$. Now either:
    \begin{itemize}
      \item $h- h_1 = 0$ (done)
      \item $\deg (h-h_1) < \deg h$. However, $h-h_1 = (u-u_1)f + (v-v_1) g$. $h-h_1 = a_e x^{e} + \text{lot}$, then $ae^{-1}(h-h_1)$ is monic of $\deg < \deg h$, and is in $S$, a contradiction. 
      
      Hence, $h$ must be unique.
    \end{itemize}
    \item $h|f, h|g$: Write \[f = q \cdot h + r.\] If $r = 0, h | f$. Else, $r = f - q \cdot h$, and thus $r \in S$, and we can write $r = f -q (uf + vg) = (f-qu)f - (qv)g$. Thus, after normalization (ie "divide out" to make monic), $r \in S$, and has a smaller degree then $h$, and we thus have a contradiction, and so $r = 0$. Thus, $h | f, h | g$.
    \item \textit{Maximality of $\deg (h)$:} Suppose $t(x) | f, t(x) | g$, thus $t(x) | (uf + vg)$, so $t | h$. Thus, $\deg t \leq \deg h$, and further $h$ has the maximal possible degree, hence $h$ is the monic common divisor of max degree.
    \item \textit{Uniqueness of GCD:} Say $h_1$ another common divisor of $f, g$ of the same degree of $h$. We have that $\deg {h} = \deg{h_1}$ and $h_1 | h$, and further $h, h_1$ monic, then $h = h_1$.
  \end{itemize}
\end{proof}

\begin{theorem}[Euclidean Algorithm (Polynomials)]
  Each
  \begin{align*}
    f = q_0 \cdot g + r_0, &\quad r_0 = 0 \text{ or } \deg(r_0) < \deg (g)\\
    g = q_1 \cdot r_0 + r_1, &\quad r_1 = 0 \text{ or }\deg(r_1)<\deg(r_0)\\
    r_0 = q_2 \cdot r_1+r_2 &\quad \cdots\\
    \vdots \\
    r_{n-1} = q_{n+1}r_n&
  \end{align*}
  We have that $r_n$, once normalized, is the $\gcd(f,g)$ (ie if $r_n(x) = a_n x^{n} + \text{lot}$, we normalize by dividing by $a_n$).
\end{theorem}
\begin{proof}
  % TODO: near identical to previous
\end{proof}

\begin{example}
  $f = x^3 - x^2 + 2x - 2$, $g = x^2 - 4x + 3 \in \mathbb{Q}[x]$.
  \begin{align*}
    f = (x^2 - 4x + 3)(x+3) + (11x-11)\\
    x^2 - 4x + 3 = (11x-11)(\frac{1}{11}x-\frac{3}{11})
  \end{align*}
  Hence, $\gcd(f,g) = \frac{1}{11}(11x - 11) = x-1$. The same process follows to find $u,v$; we have $x - 1 = \frac{1}{11}(f-g(x+3)) = \frac{1}{11}f - \frac{1}{11}(x+3)g$.
\end{example}

\begin{example}
  $\mathbb{F} = \mathbb{F}_2 = \mathbb{Z}/2\mathbb{Z} = \{0,1\}$ where $1 + 1 =0$. Take $f = x^5 + x^3 + x^2 + x, g = x^3 + x^2 + x$.\begin{align*}
    f = (x^3+x^2+x)(x^2+x+1) + x^2\\
    x^3+x^2+x = x^2(x+1) + x\\
    x^2 = x \cdot x
  \end{align*}
  Hence, $\gcd (f,g) = x$. We also have that $x = g - x^2(x+1) = g-(f-(x^2+x+1)g)(x+1) = g(1+(x^2+x+1)(x+1)) - (x+1)f = g \cdot x^3 + f\cdot (x+1)$
\end{example}

\begin{lemma}
  Let $f(x) \in \mathbb{F}[x]$ and $\alpha \in \mathbb{F}$ such that $f(\alpha) = 0$. Then, $(x-\alpha) | f(x)$
\end{lemma}

\begin{proof}
  Divide with residue: $f(x) = q_0 (x) (x-\alpha) + r$, st $r = 0$ or $\deg (r) < 1$. If $r = 0$, we are done. Now, substitute $\alpha$; $0 = f(\alpha) = \underbrace{q(\alpha)\cdot (\alpha - \alpha)}_{=0} + r \implies r = 0$.
\end{proof}

\begin{corollary}
  If $f$ has $\deg n > 0$ and $f(\alpha_i) = 0$ for distinct $\alpha_1, \dots, \alpha_n$, then $f = c \cdot \prod_{i=1}^{n} (x-\alpha_i)$. This implies that, if $\beta \neq \alpha_i$ for any $i$, then $f(\beta) \neq 0$. We can conclude that a polynomial of degree $n$ has at most $n$ distinct roots.
\end{corollary}

\begin{example}
  Do the polynomials in $\mathbb{R}[x]$ $f = x^6 + x^4 - x^2 - 1, g = x^3 + 2x^2 + x + 2$ have a common solution? They do, iff $d = \gcd(f,g)$ has a real root. In this case, $\gcd(f,g) = x^2 + 1 = (x-i)(x+i)$, so $f,g$ have no common real roots.
\end{example}

\begin{definition}[Associates]
  Two nonzero polynomials $f,g \in \mathbb{F}[x]$ are called \emph{associates} if $\exists \alpha \in \mathbb{F}, \alpha \neq 0$, st $\alpha f = g$ (we commonly denote $\mathbb{F}^{\times} = \mathbb{F}\setminus\{0\}$)
\end{definition}

\begin{remark}
  Associate polynomials have the same degree.
\end{remark}

\begin{lemma}
  This is an equivalence relation and the representatives for the equivalence are the monic polynomials.
\end{lemma}

\begin{proof}
  $f \sim f$, since $1 \cdot f = f$.\\
  If $f \sim g,$ we have $\alpha f = g \implies \frac{1}{\alpha} g = f \implies g \sim f$.\\
  If $f \sim g, g \sim h$ ie $\alpha f = g$ and $\beta g = h$, then $(\alpha \beta)f = \beta g = h$, noting that $\alpha \beta \neq 0$. Thus, this is an equivalence relation.\\
  If $f = a_n x^{n} + \text{lot}$, $a_n \neq 0$, then $\frac{1}{a_n} f \sim f$, and $\frac{a_n f} = x^{n} +\text{lot}$, a monic polynomial, hence any equivalence class has a representative which is a monic polynomial.\\
  Further, if $f, g$ monic and $\alpha f = g$, then $\alpha = 1$, hence $f = g$.
\end{proof}

\begin{definition}[Irreducible Polynomial]
  A non-constant polynomial $f$ ($\deg f > 0$) is called \emph{irreducible} if any $g | f$ satisfies $g ~ 1$ (namely, a constant) or $g \sim f$ (namely, $g = \alpha f$ for some $\alpha \in \mathbb{F}^{\times}$).\footnotemark
\end{definition}
\footnotetext{This can be seen as an analog to primes; $p \in \mathbb{Z}$ prime if $m | p \implies m = \pm 1$ or $m = \pm p$. Irreducible polynomials are the "primes of the rings of polynomials."}
\begin{remark}
  If $\deg f > 1$, $f(x)$ irreducible $\implies$ $f$ has no root in $\mathbb{F}$; if $f(\alpha) = 0$, then $f(x) = (x-\alpha)f_1(x)$, $f_1(x) \in \mathbb{F}[x]$, hence we have a non-trivial factorization since $(x-\alpha) \not\sim 1, (x-\alpha) \not \sim f \implies f$ reducible. \\The converse does not hold; consider $x^2 + 1, x^2 + 2 \in \mathbb{R}[x]$; $f(x) = (x^2+1)(x^2+2)$ is reducible, clearly, but has no real root.
\end{remark}

\begin{remark}
  Any linear polynomial, of the form $ax + b$ where $a \neq 0$, is irreducible.
\end{remark}

\begin{remark}
  Irreducibility depends on the field in question, eg $x^2 +1$ is irreducible in $\mathbb{R}[x]$, but $x^2 + 1 = (x-i)(x+i)$, so it is reducible in $\mathbb{C}[x]$.
\end{remark}

\begin{proposition}\label{prop:divirredequiv}
  Suppose\footnotemark $\deg f \geq 1$. The following are equivalent:
  \begin{enumerate}
    \item $f$ irreducible;
    \item $f | gh \implies f | g$ or $f | h$.
  \end{enumerate}
\end{proposition}

\footnotetext{Recall \cref{lemma:primediv}, in the integers}

\begin{proof}
  \textbf{1. $\implies$ 2.: } suppose $f$ irreducible and $f | gh$. If $f \not | g$, then $\gcd (f,g) = 1$. Then, we can write \begin{align*}
    1 = uf + vg, \text{ some } u(x), v(x) \in \mathbb{F}[x]\\
    \implies h = \underbrace{ufh}_{f|} + \underbrace{vgh}_{f|} \implies f | h
  \end{align*}
  \textbf{1. $\impliedby$ 2.: } suppose $f = gh$, and say wlog $f | g$. So, $f | g$ and $g|f \implies \deg g = \deg f$ and so $g = f \cdot t$, and $\deg t$ must be 0, therefore $t$ constant, and thus $h$ must be constant ie $h \sim 1$, hence $f$ irreducible.
\end{proof}

\begin{lemma}\label{lemma:irredmonicpoly}
  Any non-zero polynomial $f \in \mathbb{F}[x]$ can be written as \[f = c \cdot f_1 \cdot f_2 \cdots f_n, \]
  where all $f_i \in \mathbb{F}[x]$ are irreducible, monic, and $c \in \mathbb{F}[x]$.
\end{lemma}
\begin{proof}
  (By induction on $\deg f$)
  \begin{itemize}
    \item $\deg f = 0 \implies f$ constant ($f = f$)
    \item Suppose true for $0 \leq \deg g \leq n$ and let $f$ be a polynomial of $\deg f = n+1$. 
    
    If $f$ irreducible, $\exists c$ (leading coefficient, in fact) such that $f = c \cdot f_1$, with $f_1$ monic and irreducible (if $f \sim h$, then $f$ irreducible $\iff h$ irreducible), and we are done.

    Else, $f = f_1 \cdot f_2$ is a non-trivial factorization ie $\deg (f_1) < \deg f, \deg f_2 < \deg f$ (neither scalars). We can write, $f_1 = c_1 p_1(x) \cdots p_a(x)$ and $f_2 = c_2 p_{a+1}(x) \cdots p_b (x)$, where each $p_i$ irreducible and monic, by our assumption, hence $f = f_1 f_2 = (c_1 c_2) p_1 \cdots p_b (x)$, and our inductive step is done and thus the statement holds.
  \end{itemize}
\end{proof}

\begin{theorem}[Unique Factorization for Polynomials]\label{thm:ufpoly}
  Let $f(x) \in \mathbb{F}[x]$ be a non-zero polynomial. Then, we have \[f = c \cdot p_1 (x)^{a_1} \cdots p_r(x)^{a_r}\] where $c \in \mathbb{F}^{\times}, p_i (x)$ monic, distinct, irreducible polynomials, and $a_i > 0$. Moreover, $c$, $p_i(x)$'s, and $a_i$'s are uniquely determined.
\end{theorem}
\begin{remark}
  Existence follows from \cref{lemma:irredmonicpoly} by collecting like polynomials under $a_i$. It remains to prove uniqueness.
\end{remark}

\begin{proof}
  Because $p_i(x)$ monic, leading coefficient of rhs $c$ must be the leading coefficient of the lhs, ie $c$ determined by $f$.\\
  Suppose we have two decompositions, say \[f = c \cdot p_1 (x)^{a_1}\cdots p_r(x)^{a_r} = \tilde{c} \cdot q_1(x)^{b_1} \cdots q_s(x)^{b_s}.\] We must have $c = \tilde{c}$. Then, $r = s$ and after renaming the $q_i$, we have that $q_i = p_i$ and $a_i = b_i$. We proceed by induction on $\deg f$. 
  \begin{itemize}
    \item $\deg f = 0$: since we have irreducible polynomials which must have positive degree\footnotemark, hence the only option is $r = s = 0$, hence $f = c = \tilde{c}$.
    \item Suppose true for polynomials $h(x)$ such that $0 \leq \deg h \leq n$, and $\deg f = n+1$. Note, first, that $r \geq 1$, $s \geq 1$ (else $f$ constant). We have that \[p_1(x) | f = c \cdot q_1(x)^{b_1} \cdots q_s (x)^{b_s} \overset{\text{\cref{prop:divirredequiv}}}{\implies} \underbrace{p_1(x) | c}_{c \text{ const, not possible}} \text{ or } p_1(x) | q_i(x) \text{ for some }i. \]
    We have that $q_i (x)$ irreducible, so $p_1(x) \sim q_i(x)$, but they are both monic, so $p_1(x) = q_i(x)$. Rename, then, $q_i$ as $q_1$, ie $p_1 = q_1$. This implies, then that $c\cdot p_1^{a_1 - 1}p_2^{a_2} \cdots p_r^{a_r} = c \cdot q_1^{b_1 - 1}q_2^{b_2} \cdots q_s^{b_s}$. Then, by induction, we can "rename" each of the $q_i$, if needed, hence $p_i = q_i \forall i$, and we are done.
  \end{itemize}
\end{proof}
\footnotetext{Analog to primes $\neq 0, \pm 1$}


\begin{theorem}[Unique Factorization for Polynomials]\label{thm:uniquefactorizationpoly}
  Let $f(x) \in \mathbb{F}[x]$ be a non-zero polynomial. There exists a unique $c \in \mathbb{F}^x$ and distinct, monic, irreducible polynomials $f_1(x), \dots, f_r(x)$ with $r \geq 0$ and positive integers $a_i$ s.t. \[f(x) = c \cdot f_1(x)^{a_1} \cdots f_r(x)^{a_r}.\]
\end{theorem}

\begin{corollary}
  Let $f(x), g(x)$ be non-zero polynomials. Then, $f|g$ iff we can write \[
  f(x) = c f_1(x)^{a_1'}\cdots f_r(x)^{a_r'}, g(x) = d f_1(x)^{a_1}\cdots f_r(x)^{a_r}
  \]
  where $c,d \in \mathbb{F}^{x}$, $f_i$ are irreducible monic polynomials with $r \geq 0$, and $0 \leq a_i' \leq a_i, 0 < a_i$.
\end{corollary}

\begin{proof}
  If we have such an expression, then $g = f \cdot h$ where $h = d c ^{-1} \cdot f_1(x)^{a_1 - a_1'} \cdots f_r(x)^{a_r - a_r'}$ is a polynomial as $a_i - a_i' \geq 0$. Conversely, suppose $f | g$ so $g = fh$. Write \begin{align*}
    f = c \cdot f_1(x)^{a_1'} \cdots f_s(x)^{a_s'}, c \in \mathbb{F}^{x}, a_i' > 0\\
    h = e \cdot f_1(x)^{b_1} \cdots f_s(x)^{b_2} f_{sh}(x)^{a_{sh}} \cdots f_r(x)^{a_r}\\
    \implies g = (ce) \cdot f_1(x)^{a_1'+b_1} \cdots f_s(x)^{a_s'+b_s} f_{s+1}(x)^{a_{sh}} \cdots f_r(x)^{a_r},
  \end{align*}
  and let $d = c \cdot e$, $a_i = a_i' + b_i$ for $1 \leq i \leq s$.
\end{proof}
\begin{corollary}[GCD, LCM]
  If $f,g$ are non-zero polynomials $f(x) = c \cdot f_1(x)^{a_1} \cdots f_r(x)^{a_r}, g = d \cdot f_1(x)^{b_1} \cdots f_r(x)^{b_r}$, $c,d \in \mathbb{F}^{x}, a_i \geq 0, b_i \geq 0$, $f_i$ distinct monic irreducible. Then \begin{align*}
    \gcd (f,g) = f_1^{\min (a_1, b_1)} \cdots f_r^{\min (a_r, b_r)}\\
    \lcm (f,g) = f_1^{\max (a_1, b_1)} \cdots f_r^{\max (a_r, b_r)}
  \end{align*}
\end{corollary}

\begin{remark}
  How does one tell if a polynomial is irreducible?
  \begin{enumerate}
    \item Any linear polynomial $ax + b, a \neq 0$ is irreducible.
    \item If $f(x) \in \mathbb{F}[x]$ has degree 2 or 3, $f(x)$ reducible iff $f(x)$ has a root in $\mathbb{F}$.
    \item Over $\mathbb{C}$, the only irreducible polynomials are the linear polynomials (recall \cref{thm:complexpolynomial})
    \item Over $\mathbb{R}$ any irreducible polynomial has degree 1 or 2. \footnote{Show}
    \item Let $f(x) \in \mathbb{Q}[x]$ of degree $d$.
    \begin{enumerate}
      \item $d=1$: $f(x)$ irreducible
      \item $d = 2, 3$: $f(x)$ reducible $\iff f$ has a rational root.
      \item $d > 3$: $f(x) reducible \impliedby f$ has a root.
    \end{enumerate}
    \item Let $\mathbb{F} = \mathbb{F}_p$ where $p$ prime. Let $g(x) \in \mathbb{F}$ be a non-constant polynomial. Then, $g(x)$ has a root in $\mathbb{F}$ iff $\gcd (g, x^p - 1) \neq 1$.
  \end{enumerate}
  While no general method exists to determine reducibility, there is a general method to determine existence of roots.
\end{remark}
% TODO: add rational (prop 16.5.3)
\begin{proposition}
  Let $f(x) = a_n x^{n} + \cdots + a_1 x + a_0$ be a non-constant polynomial with integer coefficients, $a_n \neq 0$. Let $f(\frac{a}{b}) = 0$ where $(a,b) = 1$. Then, $b | a_n$, $a|a_0$.
\end{proposition}

\begin{proof}
  We have $\left(\frac{a}{b}\right)^n a_n + \left(\frac{a}{b}\right)^{n-1}a_{n-1} + \cdots + \left(\frac{a}{b}\right)a_1 + a_0 = 0$. Multiple by $b_n$ to get 
  \[
  \lefteqn{\underbrace{a^n \cdot a_n + a^{n-1} b a_{n-1} + \cdots + a b^{n-1}a_1}_{a|}\phantom{ + a_0 b^n = 0}}a^n \cdot a_n + \overbrace{a^{n-1} b a_{n-1} + \cdots + a b^{n-1}a_1 + a_0 b^n}^{b|} = 0
  \]
  Which implies \[
  \begin{cases}
    a | a_0 b^n \implies a | a_0\\
    b | a^n a_n \implies b | a_n
  \end{cases}  
  \]
\end{proof}

\begin{proposition}
  $f(x) \in \mathbb{F}[x]$ has a root $a \in \mathbb{F} \iff (x-a)|f(x) \iff \gcd (f(x), x^p - x) \neq 1$. Further, $f(x) \in \mathbb{F}[x]$ has a non-zero root $a \in \mathbb{F}\setminus \{0\} \iff (x-a) | f(x) \iff \gcd (f(x), x^{p-1} - 1) \neq 1$.
\end{proposition}

\begin{example}
  Is $-1$ a square in $\mathbb{F}_{113}$? \footnotemark
\end{example}

\footnotetext{Yes/No $\iff p \equiv_4 1,3 $}

\begin{proof}
  This is equivalent to asking is $x^2 + 1$ irred in $\mathbb{F}_{113} \iff \gcd (x^2 + 1, x^{112} - 1) \neq 1$.

  \begin{align*}
    x^{112} - 1 = (x^2 + 1)(x^{110} - x^{108}+x^{106} - \cdots + \underbrace{(-1)^{55}}_{^\frac{p-3}{2}}) - (\underbrace{(-1)^{55}}_{^\frac{p-3}{2}} + 1)\\
    \implies (x^2+1)| x^{112} -1 \implies \gcd(x^2 + 1, x^{112} - 1) = x^2 +1
  \end{align*}
  Hence, $-1$ is indeed a square ($-1 \equiv_{113} 15^2$, in fact).
\end{proof}

\section{Rings}

\subsection{Ideals}

\begin{definition}[Ideal]\label{def:ideal}
  An \emph{ideal} $I$ of $R$ is a subset of $R$ such that 
  \begin{enumerate}
    \item $0 \in I$;
    \item $x,y \in I \implies x + y \in I$;
    \item $x \in R, y \in I \implies xy \in I$.\footnotemark 
  \end{enumerate}
\end{definition}
\footnotetext{Consider 2. to state that $I$ closed under addition. 3. can be considered as a sort-of "absorption" quality; thinking about this in the more concrete case of $n \mathbb{Z}$ may make more sense. Think about this $x \cdot y$ as a "multiple" in a sense of $y$.}

\begin{remark}
  Typically, $1 \notin I$. If $I = R$, then it is; if $1 \in I$, then $\forall r \in R, r \cdot = r \in I$, hence $I = R$ (by criterion (3)). In other words, ideals are typically \emph{not} subrings. \footnote{This is a direct result of our convention of requiring subrings to contain $1$; many texts do not require subrings to contain the multiplicative elements, so in these cases ideals would then typically be subrings as well. We will not adopt this convention.}
\end{remark}

\begin{example}
  We consider some trivial examples:
  \begin{itemize}
    \item $I = \{0\}$
    \item $I = R$. 
    \item $R = \mathbb{F}$ a field, and $I \neq \{0\}$, then $I = R$. That is, any non-zero ideals of a field are trivial and generally uninteresting.
  \end{itemize}
\end{example}

\begin{definition}[Principal Ideals]
  Let $r \in R$ and let $(r) = \left\langle r\right\rangle := Rr = \{sr : s \in R\} = r R$. This is an ideal; $0 = 0 \cdot r$; $s_1 r + s_2 r = (s_1 + s_2)r \in I$; $s\cdot s_1 r = (s s_1)\cdot r \in I$.
\end{definition}

\begin{example}
  Any integer $m \in \mathbb{Z}$, $m \mathbb{Z}$ is an ideal of $\mathbb{Z}$.
\end{example}

\begin{definition}[Units of R]
  Consider a commutative ring $R$. We denote \[
  R^{\text{x}} = \{u \in R : \exists v \in R \text{ with } uv = vu = 1\}  
  \]
  the \emph{units} of $R$.
\end{definition}

\begin{remark}
  $1 \in R^{\text{x}}$. If $u_1, u_2 \in R^{\text{x}}$ then $u_1u_2 \in R^{\text{x}}$, because $\exists v_i \st v_i u_i = 1$ hence $(v_2 v_1) (u_1 u_2) = v_2(\cancelto{1}{v_1u_1})(u_2) = (v_2u_2)=1$. That is, the product of units is a unit.
\end{remark}
\begin{example}
  Consider the following examples of units:
  \begin{itemize}
    \item $\mathbb{Z}^{\text{x}} = \{\pm 1\}$
    \item $R = \mathbb{F}$ then $\mathbb{F}^{\text{x}} = \mathbb{F}\setminus \{0\}$.
    \item $\mathbb{F}[x]^\text{x} = \mathbb{F}^{\text{x}}$ (the degree of the units must be zero, hence they are simply the constants of the field.)
    \item $\mathbb{Z}[\sqrt{2}]^{\text{x}} = \{a + b\sqrt{2} : a^2 - 2b^2 = \pm 1\}$\footnotemark
  \end{itemize}
\end{example}

\footnotetext{These $(a,b)$ solve the \textit{Pell Equations}, $x^2 - 2y^2 = \pm 1$}.

\begin{definition}[Associates]
  Define $r_1, r_2 \in R$ as \emph{associates} if there $\exists u \in R^{\text{x}} \st u r_1 = r_2$.\footnotemark
\end{definition}

\footnotetext{This is an extension of the previous definition of associates for polynomials to an arbitrary ring.}

\begin{proposition}
  Take $r_1, r_2 \in R$. Then $r_1 \sim r_2$ is an equivalence relation.
\end{proposition}

\begin{proof}
  % TODO
\end{proof}

\begin{lemma}\label{lemma:relatedasssociates}
  Let $r_1, r_2 \in R$. If $r_1 \sim r_2$ then $(r_1) = (r_2)$.
\end{lemma}

\begin{remark}
  The converse does not always hold; it holds if $R$ is an \emph{integral domain.}
\end{remark}

\begin{definition}[Integral Domain]
  A ring $R$ is an \emph{integral domain} if $xy = 0 \implies x = 0 \text{ or } y = 0$.
\end{definition}

\begin{proof}
  Say $u r_1 = r_2$; then $(r_2) = R r_2 = R u r_1 = (Ru)\cdot r_1 \subseteq R \cdot r_1 = (r_1)$. Then, $r_1 \sim r_2 \implies (r_2) \subseteq (r_1)$. Equivalence relation $\implies$ symmetric, hence $r_2 \sim r_1 \implies (r_1) \subseteq (r_2)$, hence we have equality.\\
  We consider the converse; $(r) = (s) \implies r \sim s$. $r \in (r) = (s) \implies r = us$ for some $u \in R$, and $s\in (r) \implies s = vr$ for some $v \in R$. This implies then that \[(1-uv) \cdot r = 0.\]
  This gives two possibilities: $r = 0 \implies s = vr = 0$, or $r\neq 0 \implies 1 - uv = 0 \implies uv = 1 \implies u,v$ units, hence $r = u\cdot s  \implies r \sim s$ by definition. This holds only if the ring is an integral domain.
\end{proof}
\begin{theorem}
  Every ideal of $\mathbb{Z}$ is of the form $\langle m \rangle = m \cdot \mathbb{Z}$ for a unique non-negative integer $m$ which implies the ideals of $\mathbb{Z}$ are all principal and are exactly
  \[
  (0) = \{0\}, (1) = \mathbb{Z} , (2) = 2 \mathbb{Z}, (3) = 3 \mathbb{Z}, (4) = 4 \mathbb{Z}, \dots
  \]
\end{theorem}

% TODO \triangleleft 
\begin{proof}
  If\footnote{The symbol $I \triangleleft R$ denotes $I$ is a principal ideal of $R$} $I \triangleleft \mathbb{Z}$, if $I = \{0\}$ then $I = (0)$. If $I \neq \{0\}$, $\exists$ some $m \neq 0$ such that $m \in I$ and then also $- m = -1 \cdot m \in I \implies I$ contains a positive integer. Let $n \in I$ be the minimal positive element belonging to $I$. We claim that $I = (n)$.\\
  On the one hand, $n \in I \implies k n \in I \forall k \in \mathbb{Z} \implies (n) \subseteq I$. Conversely, let $t \in I$, and write \[
    t = kn + r, 0 \leq r < n.  
  \]
  If $r \neq 0$, note that $r = t - kn$, and since both $t$ and $n \implies -kn \in I$, then it must be that $r \in I$. But $r < n$, hence we have a contradiction, and it must be that $r = 0 \implies t = kn \in (n) \implies I \subseteq (n)$.
\end{proof}

\begin{theorem}
  \footnotemark Let $I \triangleleft \mathbb{F}[x]$, $\mathbb{F}$ a field. Then, $I = (0)$ or $I = (f)$ for a unique monic polynomial $f$. Moreover, if $f \neq g$ are monic polynomials, then $(f) \neq (g)$.
\end{theorem}

\footnotetext{This proof follows almost precisely from the logic of the previous proof.}

\begin{proof}
  If $I = \{0\}$ then $I = (0)$. Else, $\exists f \in I, f \neq 0$. Then, for a suitable $\alpha \in \mathbb{F}^\text{x}$, then $\alpha f$ monic, and it must be that $\alpha f \in I$. This implies that $I$ contains some monic polynomial.\\
  Let $g \in I$ be a monic polynomial of minimal degree among all nonzero polynomials of $I$. Note that $(g) = \mathbb{F}[x]\cdot g \subseteq I$. Let $h \in I$ and divide $h$ by $g$ with residue. Then, we have \[
    h = q \cdot g + r, r = 0 \text{ or } \deg (r) < \deg (g).
  \]
  Note that $r = h - qg$ where $h \in I$ and $q\cdot g \in I$, hence if $r = \neq 0$, then $\deg(r)< \deg(g)$ and we found a smaller degree polynomial in the ideal and we have a contradiction of our choice of $g$. So, we must have \[
  r = 0 \implies h = q \cdot g \implies h \in (g) \implies I \subseteq (g).
  \]
  It remains to show that $f,g$ monic and $(f) = (g) \implies f = g$. We have that $(f) = (g) \implies f \sim g$, as $\mathbb{F}[x]$ is an integral domain (\cref{lemma:relatedasssociates}), so we can write $f = u \cdot g$ for some $u \in \mathbb{F}[x] = \mathbb{F}^\text{x}  = \mathbb{F} - \{0\}$, which implies \[
  f = u \cdot g \implies x^{n} + \text{l.o.t.} = u \cdot (x^n + \text{l.o.t})   \implies u = 1 \implies f = g.
  \]
\end{proof}

\begin{example}
  Consider $x \in \mathbb{F}[x]$, and the ideal 
  \begin{align*}
    (x) = \{a_n x^n + \cdots + a_1 x \cancel{+ a_0} : a_i \in \mathbb{F}, a_0 = 0\}\\
    = \{f \in \mathbb{F}[x] : f(0) = 0\}
  \end{align*}
\end{example}

\begin{example}
  $I = \{f \in \mathbb{F}[x] : f(0) = 0, f(1) = 0\}$. Show that $I$ is an ideal, and that $I = (x \cdot (x- 1))$.
\end{example}
% TODO

\begin{definition}[Generalized Way to Create Ideals]
  Let $r_1, \dots, r_n$ be elements of a ring $R$. We write 
  \begin{align*}
  \langle r_1 ,\dots, r_n \rangle  := Rr_1 + R r_2 + \cdots + R r_n\\
  = \{\sum_{i=1}^{n} s_i r_i : s_i \in R\}
\end{align*}
For instance, $r_1 = 1 \cot r_1 + 0 \cdot r_2 + \cdots + 0 \cdot r_n \in \langle r_1, \dots, r_n\rangle$. We call this ideal the "generalize ideal"; call it $I = \langle r_1, \dots, r_n \rangle$. We show that it is indeed an ideal below.
\end{definition}

\begin{proof}
  \begin{align*}
    \text{(1)} \quad 0 = 0 \cdot r_1 + \cdots  + 0 \cdot r_n \in I\\
    \text{(2)} \quad \sum_{i=1}^n s_i r_i + \sum_{i}^n r_i r_i\\
    = \sum^n (s_i + t_i)r_i \in I\\
    \text{(3)} \quad  s \cdots \sum s_i r_i = \sum (s s_i) r_i \in I
  \end{align*}
\end{proof}

\begin{example}
  Let $m, n$ be nonzero integers. Then, we can write $\langle m, n\rangle = \langle \gcd (m,n)\rangle$.
\end{example}
\begin{example}
  Let $R = \mathbb{C}[x, y] = \{
  \sum_{i,j=0}^{N} a_{ij}x^iy^j : a_{ij}
  \}$. An ideal would be \begin{align*}
    I = \langle x, y\rangle = \{
      f(x,y) : f \text{ has no constant term, ie } a_{00} = 0
    \}
  \end{align*}
  This is because if $f \in $ LHS, then $f = f_1 \cdot x + f_2 \cdot y, f_1 , f_2 \in \mathbb{C}[x,y]$ (noting that it has no constant term), and conversely, if $f \in $ RHS, it does not have a constant term either, that is, $f = \sum a_{i,j} x^i y^j$ with $a_{00} = 0$, so we can write $f = x \cdot \sum_{i \geq 1,j} a_{ij} x^{j-1} y^{j} + y\sum_{i = 0,j} a_{ij} x^i y^{j-1}$; $i = 0 \implies j \geq 1$, and thus have "$x$ times something plus $y$ times something" and hence $f \in I$. We can equivalently write \[
  I = \{f(x,y) \in \mathbb{C}[x,y] : f(0,0) = 0\}.  
  \]
  Note that this ideal is \emph{not} a principal ideal, that is, $\not \exists$ polynomial $f(x,y) \st \langle x,y \rangle = \langle f(x,y)\rangle$. % TODO: prove.
\end{example}

\subsection{Homomorphism}

\begin{definition}[Homomorphism]
  Let $R, S$ be commutative rings.\footnotemark A function $f : R \to S$ is called a \emph{ring homomorphism} if\footnotemark \begin{enumerate}
    \item $f(1_{R}) = 1_{S} \qquad $ \textit{(identity)}
    \item $f(x+y) = f(x) + f(y) \qquad $ \textit{(respects addition)}
    \item $f(xy) = f(x)f(y) \qquad $ \textit{(respects multiplication)}
  \end{enumerate}
  $\forall x,y \in R$.
\end{definition}
\footnotetext{Throughout this section, references to arbitrary sets $R$, $S$ may be made. It is safe to assume that these are rings even if not explicitly stated.}
\footnotetext{Note the "preservation" of the properties of rings each requirement necessitates.}
\begin{proposition}
  These axioms imply the following consequences:
  \begin{enumerate}
     \item[(i)] $f(0_{R}) = 0_{S}$
     \item[(ii)] $-f(x) = f(-x)$
     \item[(iii)] $f(x-y) = f(x) - f(y)$
  \end{enumerate}
\end{proposition}
\begin{proof}
  (i) $f(0_R) = f(0_R + 0_R) = f(0_R) + f(0_R)$. Adding $-f(0_R)$ to both sides, we get $0_S = f(0_R)$.\\
  (ii) We will aim to show that $f(x) + f(-x) = 0_S$, equivalently. We have 
  \begin{align*}
    f(x) + f(-x) &= f(x+(-x)) \quad \text{by axiom 2}\\
    &= f(0_R) = 0_S \quad \text{by (1)}
  \end{align*}
  as desired.\\
  (iii) $f(x-y) = f(x + (-y)) = f(x) + f(-y) = f(x) + (-f(y)) = f(x) - f(y)$.
\end{proof}

\begin{proposition}
  $\image(f) = \{f(r) : r \in R\}$ is a subring of $S$.
\end{proposition}

\begin{remark}
  We need to check the following (ring axioms):
  \begin{enumerate}
    \item[(i)] $0, 1 \in \image (f)$
    \item[(ii)] $x_1, x_2 \in \image (f) \implies x_1 + x_2 \in \image(f)$
    \item[(iii)] $x_1, x_2 \in \image (f) \implies x_1 \cdot x_2 \in \image(f)$
    \item[(iv)] $x \in \image (f) \implies -x \in \image (f)$
  \end{enumerate}
\end{remark}
\begin{proof}
 \begin{enumerate}
  \item[(i)] $f(0_R) = 0_S, f(1_R) = 1_S$, by the previous proposition and by definition resp.
  \item[(ii), (iii)] Say $x_i = f(r_i)$; then $x_1 \overset{+}{\times} x_2 = f(r_1 ) \overset{+}{\times} f(r_2) = f(r_1 \overset{+}{\times} r_2) \in \image (f)$
  \item[(iv)] If $x = f(r), -x = -f(r) = f(-r) \in \image(f)$, from the previous proposition.
 \end{enumerate}
\end{proof}
% TODO fix above overset
\begin{definition}[Kernel]
  Let $f: R \to S$ be a homomorphism. The \emph{kernel} of $f$ is defined as \[
  \ker{F} := \{r \in R : f(r) = 0_S\} \equiv f^{-1}(0).  
  \]
\end{definition}

\begin{proposition}
  The following propositions relate to the kernel of a homomorphism:
  \begin{itemize}
    \item[(i)] $\ker (f) \triangleleft R$
    \item[(ii)] $f $ injective $\iff \ker (f) = \{0_R\}$
    \item[(iii)] $f(x) = f(y) \iff x - y \in \ker (f)$
  \end{itemize}
\end{proposition}

\begin{remark}
  To show that some $t \in \ker (f)$, we need only to show that $f(t) = 0_S$.
\end{remark}

\begin{proof}
  \begin{itemize}
    \item[(i)] We show each axiom: $f(0_R) = 0_S \in \ker(f)$; $x,y \in \ker(f) \implies f(x)  + f(y) = 0_S + 0_S = 0_S$; $f(rx) = f(r)f(x) = f(r) \cdot 0_S = 0_S$.
    \item[(ii)] Suppose $f$ injective. Then, $0_R$ is the unique element mapping to $0_S$, by definition of an injective function. Hence, $\ker f = \{0_R\} = (0_R)$. Conversely, suppose $\ker f = \{0_R\}$ and that $f(x) = f(y)$. Note that $f(x - y) = f(x) - f(y) = f(x) - f(x) = 0_S \implies x - y \in \ker (f) \implies x - y = 0_R \implies x = y$.
    \item[(iii)] $f(x) = f(y) \iff f(x) - f(y) = 0_S \iff f(x - y) = 0_S \iff x - y \in \ker (f)$.
  \end{itemize}
\end{proof}

\begin{corollary}
  Let $s \in S$ and let $f^{-1}(s) = \{r \in R : f(r) = s\}.$ Then, either $f^{-1}(s) = \varnothing$, or $f^{-1}(s) = x + \ker (f) = \{x + r : r \in \ker (f)\} \subseteq R$ for any $x \st f(x) = s$.
\end{corollary}

\begin{proof}
  If $f^{-1}(s) \neq \varnothing, \exists x \in R \st f(x) = s$. If $x + r \in x + \ker R$, then $f(x + r) = f(x) + f(r) = s + 0_S = s$. Hence, $f^{-1}(s) \supseteq x + \ker (f)$.

% TODO; add ref
  Suppose $y \in f^{-1}(s) \implies f(x) = f(y) = s$. This implies $r = y - x \in \ker f$ (by previous proposition). Note that $x+r = y$; hence $y \in x + \ker (f) \implies f^{-1}(s) \subseteq x + \ker (f)$.
\end{proof}

\begin{example}
  $R = \mathbb{Z}$, $S = \mathbb{Z}/n \mathbb{Z}$ where $n \geq 1 \in \mathbb{Z}$. Take $f : R \to S$ where $f(a) = a \mod n = \bar{a}$. This is a ring homomorphism:
  \begin{itemize}
    \item $f(1) \equiv_n 1$, the identity of $\mathbb{Z}/n \mathbb{Z}$.
    \item $\overline{a + b} = \bar{a} + \bar {b}$.
    \item $\overline{ab} = \bar{a} \cdot \bar{b}$.
  \end{itemize}
  This is surjective, hence $\image (f) = \mathbb{Z}/n\mathbb{Z}$. We have that $\ker (f) = \{a \in \mathbb{Z} : \bar{a} \equiv_n 0\} = (n) = n \mathbb{Z}$.

  Now what is $f^{-1}(\overline{1})$? Take some $x \in \mathbb{Z}$. $f(x) = \overline{x} = \overline{1};$ take $x = 1$, then $f^{-1}(1) = 1 + n \mathbb{Z}$. Generally, then, we have $f^{-1}(\overline{r}) = r + n \mathbb{Z}$.
\end{example}

\begin{example}
  Let $\mathbb{F}$ be a field and $b \in \mathbb{F}$ a fixed element. $\varphi : \mathbb{F}[x] \to \mathbb{F}$, where $\varphi(f(x)) = f(b)$. So, $f(x) = a_n x^n + \cdots + a_1 x + a_0$, $\varphi (f(x)) = a_n b^n + \cdots + a_1 b + a_0$. This is a ring homomorphism.
  % TODO: show
  \begin{itemize}
    \item $f(1) = 1$
  \end{itemize}
  We have too that $\varphi$ is surjective; given $c \in \mathbb{F}$, we can show that $\varphi(x + (c - b)) = b + (c- b) = c$. 

  $\ker \varphi = (x-b)$ % TODO: show
\end{example}

\begin{example}
Let $R, S$ be rings. Then, $R \times S$ is a ring. % TODO  
\end{example}

\begin{example}
  Consider the map \[
  R \to R \times S, \quad r \mapsto (r,0).
  \]
  This is \emph{not} a ring homomorphism since $f(1) = (1,0) \neq (1,1)$ (that is, unless $0_s = 1_s$, that is, $S$ is the zero ring).

  OTOH, take 
  \begin{align*}
    \varphi : R \times S \to R, \quad (r,s) \mapsto r\\
    \psi : R \times S \to S, \quad (r,s) \mapsto s
  \end{align*}
  These are indeed ring homomorphisms. % TODO

  We also have \[\ker \varphi = \{0\} \times S, \ker \psi = R \times \{0\}.\]
\end{example}

\begin{example}
  Take a polynomial in $\mathbb{R}[x]$ and fix $\alpha_1 < \alpha_2 < \cdots < \alpha_n \in \mathbb{R}$. Take \[
  \varphi : \mathbb{R}[x] \mapsto \mathbb{R}^n, \quad f(x) \mapsto (f(\alpha_1), f(\alpha_2), \dots, f(\alpha_n)).
  \]
  This is a homomorphism. % TODO
  We also have that $\varphi$ is surjective. Let $$e_i = \cdots(0, \dots, 0, 1, 0, \dots, 0),$$ ie a unit vector where the $i$th entry is 1. Take \begin{align*}
    f_i(x) = \prod_{j=1, j \neq i}^n (x - \alpha_j)/ \prod_{j=1, j \neq i}^n (\alpha_i-\alpha_j).
  \end{align*}
  Note that $f_i(\alpha_i) = 1$ and $0$ for all other $\alpha_j$, and thus $\varphi (f_i) = e_i$. Further, $\varphi(r_1 f_1 + \cdots + r_n f_n) = \sum_{i=1}^n \varphi(r_i f_i) = \sum_{i=1}^n \varphi(r_i) \varphi(f_i) = \sum_{i=1}^{n} r_i e_i = (r_1, \dots, r_n)$, hence $\varphi$ surjective.

  Finally, we have that $\ker \varphi = \langle \prod_{i=1}^{n}(x-\alpha_i)\rangle$.
\end{example}

\subsection{Cosets}
\begin{definition}[Coset]
  Let $R$ be a ring and $I \idealof R$. A \emph{coset} of $I$ is a subset of $R$ of the form \[a + I = \{a + i : i \in I\},\] where $a \in R$.
\end{definition}
\begin{remark}
  Note that the coset, while defined with respect to $I$, need not be a subset of $I$, but is by definition a subset of the ring $R$.
\end{remark}

\begin{definition}[Relation on Cosets]
  Let $R$ be a commutative ring and $I \triangleleft R$. Define a relation on $R$ as $x \sim y$ if $x -y \in I$.
\end{definition}

\begin{lemma}
  The following relate to relation defined previously.
  \begin{enumerate}
    \item This is an equivalence relation.
    \item Every equivalence class is of the form $x + I$, where $x+I$ is called a \emph{coset} of $I$, for some $x \in R$.
    \item $x + I = y + I \iff x - y \in I$.
    \item Either $(x+I) \cap (y+I) = \varnothing$ or $x + I = y + I$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  \begin{enumerate}
    \item (i) $x \sim x \impliedby x - x = 0$. $x - x = 0 \in I$ by definition. (ii) $x \sim y \implies x - y \in I \implies -1 (x-y) \in I \implies y-x \in I \implies y \sim x$, again by definition. (iii) $x \sim y$, $y \sim z \implies x -y, y - z \in I \implies x - y +  y - z \in I \implies x -z \in I \implies x \sim z$, as the ideal is closed under addition, hence $\sim$ is an equivalence relation.
    \item $x + I = \{x + t : t \in I\} \subseteq R$. Suppose $y \in x + I,$ then $y = x + t$ then $x - y = x - (x+t) = -1\cdot t \in I$. That is, $x \sim y$. Suppose $y \sim x$. Then, $y - x =: t \in I \implies y = x + (y-x) = x + t \in x+ I \implies $ equivalence class of $x$ is $x + I$.
    \item This is equivalent to saying the equivalence class of $x$ is the equivalence class of $y$ iff $x \sim y$, which follows by definition.
    \item Follows by the fact that equivalence classes partition the set they are defined on (recall \cref{thm:equivclass}).
  \end{enumerate}
\end{proof}

\begin{example}
  Say $R = \mathbb{Z}, I = n \mathbb{Z}$. Then, the cosets are just the congruence classes ($n \mathbb{Z}, 1 + n \mathbb{Z} , \dots, (n-1) + n \mathbb{Z}$) $\mod n$.
\end{example}

\subsection{Quotient Rings: \texorpdfstring{The Ring $R/I$}{The Ring R/I}}

\begin{definition}[Quotient Ring]
  Consider \footnotemark $R / I$. We define operations as \[
  (x+I) + (y+I) := (x+y) + I, \quad (x + I) \cdot (y+I) := (x\cdot y) + I.  
  \]
  Equivalently, letting $\overline{x} = x + I$, we write \[
  \overline{x}  + \overline{y} = \overline{x+y}, \quad \overline{x} \cdot \overline{y} = \overline{x\cdot y}.
  \]

\end{definition}


\footnotetext{Recall how we defined the elements of the ring $\mathbb{Z}/n \mathbb{Z}$. This can be seen as a generalization of this idea; read "R" mod "I".}

\begin{remark}
  By this definition, we can see that every element of $R / I$ is a coset, that is, of the form $x + I$; this is not unique, however, as it is possible that $x + I = y + I$ despite $x \neq y$.
\end{remark}

\begin{theorem}[$R/I$ is a Commutative Ring]\label{thm:rmodicommutativering}
  $R/I = \{\overline{x} : x \in R\}$ is a commutative ring, where $0 = \overline{0} = I, 1 = \overline{1} = 1 + I$. Moreover, the function \[
  \pi : R \to R /I, \quad x \mapsto \overline{x},  
  \]
  is a surjective ring homomorphism with $\ker \pi = I$.
\end{theorem}

\begin{corollary}
  Any\footnotemark ideal is the kernel of some ring homomorphism.
\end{corollary}

\footnotetext{Direct consequence of \cref{thm:rmodicommutativering}}
\begin{proof}(Of \cref{thm:rmodicommutativering})
  We first sow that the operations are well defined, that is, if $\bar{x} = \bar{x}_1, \bar{y} = \bar{y}_1$, then $\overline{x+y} = \overline{x_1+y_1}$, and $\overline{x} \cdot \overline{y} = \overline{x_1 \cdot y_1}$. \footnote{For instance, in $\mathbb{Z}/8 \mathbb{Z}, $ we have that $\overline{3} + \overline{10} = \overline{3 + 10}= \overline{13} = \overline{5}$, which is equivalent to saying $\overline{3} + \overline{2} = \overline{3+2} = \overline{5}$. We aim to show this holds for general $R/I$.}
  We have, then, \begin{align*}
    x - x_1 \in I, y - y_1 \in I \implies (x+y) - (x_1 + y_1) = \underbrace{(x - x_1)}_{\in I} + \underbrace{(y- y_1)}_{\in I} \in I\\
    xy - x_1 y_1 = \underbrace{x}_{\in R}(\underbrace{y - y_1}_{\in I}) + \underbrace{y_1}_{\in R}(\underbrace{x - x_1}_{\in I}) \in I,
  \end{align*}
  hence the operations are well defined. We now verify (some of) the ring axioms:
  \begin{enumerate}
    \item $\overline{x} + \overline{y} = \overline{x+y} = \overline{y+x} = \overline{y}+\overline{x}$
    \item $\overline{0} + \overline{x} = \overline{0+x} = \overline{x}$
    \item $\overline{x} + (\overline{-x}) = \overline{x+(-x)} = \overline{0} \implies \overline{x}$ has an inverse for addition, $- \overline{x} = \overline{-x}$
    \item $\cdots$
    \item $\cdots$
    \item $\cdots$
    \item $\cdots$
    \item $\overline{x}(\overline{y} + \overline{z}) = \overline{x} \cdot \overline{x+y} = \overline{x(y+z)} = \overline{xy+yz} = \overline{xy} + \overline{xz} = \overline{x} \cdot \overline{y} + \overline{x} \cdot \overline{z}$,
  \end{enumerate}
  hence, it is a commutative ring.

  Now consider the map $\pi: R \to R/I, \pi(x) = \overline{x}$. We verify it is indeed a ring homomorphism:
  \begin{enumerate}
    \item $\pi(1) = \overline{1} = 1_{R/I}$
    \item $\pi(x+y) = \overline{x+y} = \overline{x} + \overline{y} = \pi(x) + \pi (y)$
    \item $\pi (x\cdot y) = \overline{x\cdot y} = \overline{x} \cdot \overline{y} = \pi (x) \cdot \pi (y)$
  \end{enumerate}
  Hence, $\pi$ is indeed a ring homomorphism. Its kernel is:
  \[
  \ker (\pi) = \{x \in R : \pi(x) = \overline{0}\} = \{x \in R : x + I = 0 + I = I\} = \{x \in R: x \sim 0\}  = \{x \in R : x \in I\} = I.
  \]
\end{proof}

\begin{example}[Of $R/I$'s]
  \begin{enumerate}
    \item $R = \mathbb{Z}, I = n \mathbb{Z}$, $a + n \mathbb{Z} = \overline{a} = a \mod n$, that is, this is modular arithmetic on the integers. The homomorphism is $\mathbb{Z} \to \mathbb{Z}/n\mathbb{Z}, a \mapsto \overline{a}$, which has a kernel of $n \mathbb{Z}$.
    \item $R = \mathbb{F}[x], I = \langle f(x)\rangle, f(x)$ monic, non-constant polynomial. (We have that $ \langle f(x)\rangle =  \langle \alpha f(x)\rangle \forall \alpha \in \mathbb{F}^{\times},$ so monic wlog; a constant polynomial $f = \alpha, \alpha \in \mathbb{F}^{\times}$ would have $I = \mathbb{F}[x]$ so $R/I = \{0\}$, an uninteresting case, so we require non-constant $f$.)
    
    In this context, $g(x) \sim h(x) \iff g(x)-f(x) \in \langle f(x)\rangle \iff f(x) | (g(x)-h(x))$, that is, $\overline{g} = \overline{h} \iff f | (g-h)$.
  \end{enumerate}
\end{example}

\begin{example}
  Consider $\mathbb{R}[x]/\langle x^2 + 1\rangle$. We claim that $\overline{a_1 + b_1 x} = \overline{a_2 + b_2 x} \implies a_1 = a_2, b_1 = b_2$. We can check:
  \begin{align*}
    \overline{a_1 + b_1 x} = \overline{a_2 + b_2 x} \iff (x^2 + 1) | (a_1 - a_2) + (b_1 - b_2)x,
  \end{align*}
  but this is impossible, since the RHS is linear and the LHS is quadratic, \emph{unless} the RHS is $0$, hence, that $a_1 - a_2 = 0 \iff a_1 = a_2$ and $b_1 - b_2 = 0 \iff b_1 = b_2$, as desired.

  Further, we claim that any coset is represented by some $a+bx$. Suppose $\overline{g}$ a coset. Then,
  \begin{align*}
    g = q \cdot (x^2 + 1) + r(x), \quad, r(x) = 0 \text{ or } \deg (r(x)) < 2\\
    \implies r(x) = a, a \in \mathbb{R} \text{ or } r(x) = a + bx, a, b \in \mathbb{R}\\
    \implies r(x) = a+bx, a, b \in \mathbb{R},
  \end{align*}
  that is, $r(x)$ can be written as $a +bx$ for $a,b$ in the field or zero. Hence, we have $g(x) - r(x) = q \cdot (x^2 +1),$ and since $(x^2 + 1 )| q \cdot (x^2 + 1),$ then $g(x) \sim r(x) \implies \overline{g} = \overline{r}$. Hence, we can conclude that every element of $\mathbb{R}[x]/\langle x^2 + 1 \rangle$ is of the form $\overline{a + bx}, a, b \in \mathbb{R}$, for unique $a,b$.

  Operations in this case would work as:
  \begin{align*}
    \overline{a_1 + b_1 x} + \overline{a_2 + b_2 x} &= \overline{(a_1 + a_2) + (b_1 + b_2)x}\\
    \overline{a_1 + b_1 x} \cdot \overline{a_2 + b_2 x} &= \overline{(a_1 + b_1x)(a_2 + b_2 x)} = \overline{a_1a_2 + (a_1 b_2 + a_2 b_1)x + b_1 b_2 x^2}
  \end{align*}
  But note that $x^2 = (x^2+1)-1 \implies \overline{x^2} = \overline{-1}$, so $b_1 b_2 x^2 = - b_1 b_2$, so this simplifies to \[
    \overline{a_1a_2 + (a_1 b_2 + a_2 b_1)x - b_1b_2} = \overline{(a_1a_2- b_1b_2) + (a_1 b_2 + a_2 b_1)x }.
  \]
  But note the similarity to multiplication in $\mathbb{C}$. In this way, we can define a bijection\footnotemark\[\mathbb{R}[x]/(x^2+1) \cong \mathbb{C}, \quad a + bi \mapsto \overline{a+bx}.\]
\end{example}
\footnotetext{Note that $A \cong B$ means that $A$ is \emph{isomorphic} to $B$.} 

\begin{remark}
  This concept works generally. % TODO: show
\end{remark}

\begin{lemma}\label{lemma:completesetofreppoly}
  Suppose $n = \deg (f)\geq 1$. Then, a complete set of representatives for the cosets is \[\circledast = \{g(x) : \deg g < n\} = \{ b_{n-1} x^{n-1} + \cdots + b_0 : b_i \in \mathbb{F}\}.\]
\end{lemma}

\begin{proof}
  Take $h(x) \in \mathbb{F}[x]$, and write $h(x) = q(x)f(x) + r(x)$, where either $r(x) = 0$ or $\deg r < n$. Then, $h(x) -r(x) = q(x)f(x) \in I \implies h(x) + I = r(x) + I$ (that is, $h$ and $r$ are $\sim$). So, any coset is represented as an element of $\circledast$. It remains to show that this holds for any coset, that is, if $g_1, g_2 \in \circledast$ and $g_1 + I = g_2 + I \implies g_1 = g_2$. We have that $g_1 - g_2 \in I = f(x) \cdot \mathbb{F}[x]$ for any nonzero $f, \deg f \leq n$. Moreover, $\deg (g_1 - g_2) < n,$ hence, $g_1 = g_2$.
\end{proof}

\begin{example}
  Take $f(x) = x^2 + 1$; here, $\circledast =\{a x + b : a,b \in \mathbb{F}\}$.
\end{example}

\begin{remark}
  Consider the analog to integer modular arithmetic. For addition, we have that $\overline{g_1} + \overline{g_2} = \overline{g_1 + g_2}, \deg{g_1 + g_2} < n$. For multiplication, we have $\overline{g_1}\cdot\overline{g_2} = \overline{g_1g_2}$. But now,$\deg{g_1 g_2}$ is potentially $\geq n$, so we write $\overline{g_1 g_2} = \overline{r},$ where $r$ the residue of dividing $g_1 g_2$ by $f$ (which then must have degree $<n$).
\end{remark}

\begin{theorem}\label{thm:fieldcontstructionpoly}
  Let $\mathbb{F}$ be a field. Let $f(x) \in \mathbb{F}$ be a non-constant irreducible polynomial. Then, $R = \mathbb{F}[x]/(f(x))$ is a field \emph{containing} $\mathbb{F}$. 
  
  Moreover, if $\# \mathbb{F} = q, \deg(f) = n$, then $\# R = q^n$.
\end{theorem}

\begin{example}
  Take, $\mathbb{F}_2$, and consider $\mathbb{F}[x]/(x^2 + x+ 1)$; this is a field with $4$ elements. Namely, they are $0, 1, x, 1 + x$; these are the only polynomials of $\deg < 2$ with coefficients in $\mathbb{F}_2$. We can write operations in the field:
  \begin{center}
    \text{(Addition)}
    \begin{tabular}{c|cccc}
      + & 0 & 1 & $x$ & $1+x$\\
      \hline
      0 & 0 & 1 & $x$ & $x+1$\\
      1 & 1 & 0 & $x+1$ & $x$\\
      $x$ & $x$ & $x+1$ & 0 & 1\\
      $1 + x$ & $x +1$ & $x$ & 1 & 0
    \end{tabular}\\
    \text{(Multiplication)}
    \begin{tabular}{c|cccc}
      $\cdot$ & 0 & 1 & $x$ & $x+1$\\
      \hline
      0 & 0 & 0 & 0 & 0\\
      1 & 0 & 1 & $x$ & $x+1$ \\
      $x$ & 0 & $x$ & $x+1$ & 1\\
      $x + 1$ & 0 &$ x+1$ & 1 & $x$
    \end{tabular}
  \end{center}
\end{example}

\begin{proof}(Of \cref{thm:fieldcontstructionpoly}) We have shown previously that $\mathbb{F}[x]/I$ a commutative ring; further, $\overline{0} \neq \overline{1},$ because of the set $\circledast$ above. Hence it remains to show that there exists inverses.\footnotemark

  Let $\overline{g} \in \mathbb{F}[x]/(f(x)),$ $\overline{g} \neq \overline{0}$, that is, $f \not|g$. This implies, moreover, that $\gcd (f,g) = 1$, since $f$ irreducible (the divisors of $f$ are thus $1$ and $f$; $f$ does not divide $g$ as shown, hence the $\gcd$ is 1). This implies that $\exists u(x), v(x) \in \mathbb{F}[x] \st 1 = u(x)f(x) + v(x)g(x) \implies \overline{1} = \overline{u(x) f(x)} + \overline{v(x)g(x)}$. But $u(x) f(x)$ a multiple of $f(x)$ hence $\in I \implies \overline{u(x)f(x)} \in \overline{0} \implies \overline{1} = \overline{0} + \overline{v(x)}\overline{g(x)} \implies \overline{v(x)}\overline{g(x)} = \overline{1},$ that is, $v(x)$ is the inverse wrt multiplication of $g(x)$, as desired.
  
  % TODO prove last statement
\end{proof}

\footnotetext{Note the similarities to proving that $\mathbb{Z}/p\mathbb{Z}$ where $p$ prime a field; that is, yet again, primes in $\mathbb{Z}$ are analogous to irreducible polynomials in $\mathbb{F}[x]$.}


\begin{example}
  We construct a field with 25 elements. Take $\mathbb{F}_5 = \mathbb{Z}/5\mathbb{Z}$ and $f(x) = x^2-2$ (irreducible $\mod 5$). Take $\mathbb{L} = \mathbb{F}_5[x]/(x^2 - 2)$, which is then a field with $25$ elements by \cref{thm:fieldcontstructionpoly}, spec, of the form $\{a + bx: a, b \in \mathbb{F}_5\}$.
\end{example}

\begin{remark}
  The polynomial $t^2 -2$ is irreducible in $\mathbb{F}_5$, but it actually has a root in $\mathbb{L}$ as defined above. Namely, the root is $x$ ($\overline{x}$). To check: $\overline{x}^2 - \overline{2} = \overline{x^2 - 2} = \overline{0}$.\footnotemark
\end{remark}

\footnotetext{"You're not being cheated, its a tautology."}

\begin{remark}
  We could have defined $\tilde{\mathbb{L}} = \mathbb{F}_5[x]/(x^2 - 3)$; these are isomorphic fields, that is, $\tilde{\mathbb{L}}\cong \mathbb{L}$. Moreover, we have that $t^2 - 3$ has a root in $\tilde{\mathbb{L}},$ so it must have a root in $\mathbb{L}$ as well.

  Take $(ax + b) \in \mathbb{L}$. We want that $(ax+b)^2  =3$. That is,
  \begin{align*}
    (ax+b)^2 = a^2 x^2 + 2abx + b^2\\
    = 2a^2 + 2abx + b^2 \\
    = 2abx + (b^2 + 2a^2) = 3 \implies a = 0 \text{ or } b = 0
  \end{align*}
  In the case $a = 0$, we have that $b^2 = 3 \implies 3$ a square, which is not true in $\mathbb{F}_5$. Taking $b = 0$, then, we have $2a^2 = 3 \implies a = \pm 2$. We can verify:
  \[
  \overline{3} = (\overline{2} \overline{x})^2 \in \mathbb{L}.
  \]
\end{remark}

\begin{remark}
  $L$ contains $\mathbb{F}$ is not very precise; more specifically, we have that $\exists$ a map $\mathbb{F} \to L,$ $\alpha \mapsto \overline{\alpha} = \alpha + \langle f(x) \rangle$. This an injective ring homomorphism, and thus $\mathbb{F} \cong \Im(\mathbb{F})$, that is, $\mathbb{F}$ is isomorphic to the image of $\mathbb{F}$.
\end{remark}

\begin{theorem}
  Let $g(t) \in \mathbb{F}[t]$ be a non-constant polynomial. Then, $\exists$ a field $L \supseteq \mathbb{F} \st g$ has a root in $L$.
\end{theorem}

\begin{proof}
  WLOG, assume $g(t)$ irreducible. Take another variable $x$, and let $L = \mathbb{F}[x]/\langle g(x) \rangle$; this is a field as $g$ irreducible, and again, it contains $\mathbb{F}$ (that is, a field isomorphic to $\mathbb{F}$). Then, in $L$, the element $\overline{x}$ solves $g(t) = a_n t^n + \cdots + a_0, a_i \in \mathbb{F}$. We have, $g(\overline{x}) = \overline{a_n} \overline{x}^{n} + \cdots + \overline{a_0} = \overline{a_n x^n + \cdots a_0} = \overline{g(x)} = g(x) + \langle g(x)\rangle = \langle g(x) \rangle = 0_L$.
\end{proof}

\begin{example}
  $\mathbb{F} = \mathbb{R}, g(t) = t^2 + 1.$ $L = \mathbb{R}[x]/\langle x^2+1\rangle, \overline{x}$ a root of $t^2 + 1$. In this case, we can denote $\overline{x} = i$, that is, $i = \sqrt{-1}$; $L \cong \mathbb{C}$.
\end{example}

\subsection{Isomorphisms}

\begin{definition}[Isomorphism]
  Let $f : R \to S$ be a ring homomorphism. If $f$ bijective, we say that $R$ is \emph{isomorphic} to $S$, and denote $R \cong S$. We say that $f$ is an \emph{isomorphism} between $R$ and $S$.
\end{definition}


\begin{theorem}[First Isomorphism Theorem]\label{thm:firstiso}
  Let $\varphi: R \to S$ be a surjective homomorphism of rings. Let $I = \ker \varphi$. Then, $R/I \cong S$.
\end{theorem}

\begin{proof}
  Denote the elements of $R /I$ by $\overline{r}$. Define $\varPhi : R/I \to S,$ $\varPhi(\overline{r}) = \varphi(r)$. We show this is a ring homomorphism:
  \begin{itemize}
    \item (Well defined) if $\overline{r} = \overline{r_1},$ we aim to show that $\varphi(r) = \varphi(r_1)$. $\overline{r} = \overline{r_1} \implies r - r_1 = a \in I = \ker \varphi$. $\varphi(r) = \varphi(a+r_1) = \varphi(a) + \varphi(r_1) = 0 + \varphi(r_1) = \varphi(r_1)$.
    \item (Homomorphism) $\varPhi(\overline{r} +/\cdot \overline{s}) = \varPhi (\overline{r +/\cdot \overline{s}}) = \varphi(r + /\cdot s) = \varphi(r) +/\cdot \varphi(s) = \varPhi(\overline{r}) +/\cdot \varPhi(\overline{s})$.
  \end{itemize}
  To show $\varPhi$ bijective:
  \begin{itemize}
    \item (Surjective) Given $s \in S, \exists r \in R \st \varphi(r) = s$, since $\varphi$ surjective. Then, $\varPhi (\overline{r}) = \varphi(r) = s \implies \varPhi$ surjective.
    \item (Injective) This is equivalent to showing $\ker \varPhi = \{\overline{0}\}$. Suppose $\varPhi(\overline{r}) = 0_S \implies \varphi(r) = 0_S \implies r \in \ker \varphi = I \implies \overline{r} = 0_{R/I}$
  \end{itemize}
  Hence, $\varPhi$ a bijective ring homomorphism and so $R/I \cong S$.
\end{proof}

\begin{example}
Let $R = \mathbb{R}[x], S = \mathbb{C}$. Let $\varphi : R \to S,$ $\varphi(f(x)) = f(i)$. $\varphi$ is a homomorphism of rings:
\[
\varphi (f +/\cdot g) = (f+/\cdot g)(i) = f(i) +/\cdot g(i); \quad \varphi (1) = 1.
\]
Let $I = \ker \varphi$. Note that $x^2 + 1 \in I (i^2 + 1 = 0), \implies \langle x^2 + 1 \rangle \subseteq I$. We know, further, that $I = \langle g(x)\rangle$ for some $g(x) \in \mathbb{R}[x]$ (any ideal of $\mathbb{R}[x]$ principal), so $x^2 + 1 \in I \implies g(x) | (x^2+1)$. But $x^2 + 1$ is irreducible, hence $g(x) \sim 1 \implies I = \mathbb{R}[x]$ or $g(x) \sim x^2 + 1 \implies I = \langle x^2 + 1\rangle$. This first case is not possible, since this implies $1 \in \mathbb{R}[x],$ since $\varphi(1) = 1 \neq 0,$ hence $g(x) = x^2 + 1 \implies I = \langle x^2 + 1 \rangle$, and thus by \nameref{thm:firstiso}, $\mathbb{R}[x]/\langle x^2 + 1\rangle \cong \mathbb{C}$.
\end{example}

\begin{theorem}[Chinese Remainder Theorem]\label{thm:chineseremaindertheorem}
  Let $m,n$ be relatively prime positive integers. Then, $\mathbb{Z}/mn\mathbb{Z} \cong \mathbb{Z}/m \mathbb{Z} \times \mathbb{Z}/n \mathbb{Z}$.
\end{theorem}

\begin{proof}
Define a function $\varphi : \mathbb{Z} \to \mathbb{Z}/m\mathbb{Z} \times \mathbb{Z}/n\mathbb{Z}$, $\varphi(a) = (a \mod m, a \mod n)$. We show $\varphi$ a ring homomorphism:
\begin{align*}
\varphi(a +/\cdot b) = (a+/\cdot b \mod m, a + /\cdot b \mod n) \\
= (a \mod m + /\cdot b \mod m, a \mod n + /\cdot b \mod n)   \\
= (a \mod m, a \mod n) +/\cdot (b \mod m, b \mod n)\\
= \varphi(a) +/\cdot \varphi(b)\\
\varphi(1) = (1 \mod m, 1 \mod n) = 1_{\mathbb{Z}/m\mathbb{Z} \times \mathbb{Z}/n \mathbb{Z}}
\end{align*}
We also have \begin{align*}
\ker \varphi  = \{a  \in \mathbb{Z} : \varphi(a) = (a \mod m, b \mod n) = (0,0)\} \\
= \{a : m | a \text{ and } n| a\} = \{a : \lcm (m,n) | a\} = \{a : mn | a\} = mn\mathbb{Z}
\end{align*}

Let $S = \im \varphi$ which is a subring of $\mathbb{Z}/m \mathbb{Z} \times \mathbb{Z}/n \mathbb{Z}$. Then, $\varphi :\mathbb{Z} \to S$ is a surjective ring homomorphism with kernel $mn \mathbb{Z}$, and so by \nameref{thm:firstiso}, $\mathbb{Z}/mn \mathbb{Z} \cong S$. Note that the LHS has $m \cdot n$ elements, hence $S$ must have $m \cdot n$ elements as well, and thus $S = \mathbb{Z} /m \mathbb{Z} \times \mathbb{Z}/n \mathbb{Z}$. Thus, $\mathbb{Z}/mn \mathbb{Z} \cong \mathbb{Z}/m\mathbb{Z} \times \mathbb{Z}/n\mathbb{Z}$.

We can alternatively prove surjectivity directly. Since $\gcd(m,n) = 1, \exists u,v \in \mathbb{Z} \st 1 = um + vn$, hence we have \[
\varphi(um) = (um \mod m, 1 - vn \mod n) = (0, 1)
\]
and
\[ 
  \varphi(vn) = (1 - um \mod m, vn \mod n) = (1,0)
\]
Hence, \begin{align*}
\varphi(aum + bvn) = \varphi(aum) + \varphi(bvn) = \varphi(\underbrace{um + \cdots +um}_{a \text{ times}}) +  \varphi(\underbrace{vn + \cdots +vn}_{b \text{ times}})\\
= a \varphi(um) + b \varphi(vn)\\
= a (0,1) + b(1,0)\\
= (0, a) + (b,0) = (b, a),
\end{align*}
hence $\varphi$ surjective. Again, the kernel is $\ker \varphi = mn \mathbb{Z}$ and so $\mathbb{Z}/mn\mathbb{Z} \cong \mathbb{Z}/m\mathbb{Z} \times \mathbb{Z}/n\mathbb{Z}$
\end{proof}

\begin{example}[Application of \nameref{thm:chineseremaindertheorem}]
  Let $m = 11, n = 13$. Find an integer $x \st$ $x \equiv_{11} 2$ and $x \equiv_{13} 3$.
  \begin{proof}
    We can express $1 = \gcd (11, 13) = um + vn = 11u + 13 v$. Working out the Euclidean algorithm, this yields $u = 6$ and $v = 5$, that is, $1 = 6 \cdot 11 - 5 \cdot 13 = 66 - 65$. We have \[
    66 \mapsto(0, 1) \in \zmod{11} \times \zmod{13},
    \]
    and \[-65 \mapsto (1,0) \in \zmod{11} \times \zmod{13}.\]
    Hence, $3 \cdot 66 + 2 \cdot -65 \mapsto(2, 3) \in \zmod{11}\times\zmod{13}$, so $x = 3 \cdot 66 + 2 \cdot -65 = 68$.
  \end{proof}
\end{example}

\section{Groups}
\subsection{Definitions}
\begin{definition}[Group]
  A \emph{group} $G$ is a non-empty set with an operation \[
  G \times G \to G, \quad (a,b) \mapsto a \ast b,  
  \]
  s.t. \begin{enumerate}
    \item (Associative) $a \ast (b \ast c) = (a\ast b)\ast c$
    \item (Two-Sided Identity) $\exists$ an element of $G$, denoted $1_G$ s.t. $\forall a \in G, 1_G \ast a = a \ast 1_G = a$
    \item (Two-Sided Unit) $\forall a \in G, \exists b \in G \st a \ast b = b \ast a = 1_G$
  \end{enumerate}
\end{definition}

\begin{proposition}[Basic Properties of Groups]
  The following are direct consequences of the definition of a group:
  \begin{enumerate}
    \item $1_G$ unique: if $c \in G \st a \cdot c = c \cdot a = a \forall a \in G,$ then $c = 1_G$
    \item Given $a \in G, b \st a \ast b = b \ast a = 1_G$ is unique: if $a \ast c = c \ast a = 1_G,$ then $c = b$. We denote $b = a^{-1}$.
    \item $(a_1 \ast a_2)^{-1} = a_2^{-1} \ast a_1^{-1}$.
    \item $ab = ac \implies b = c$
    \item Define for $a \in G, n \in \mathbb{Z}$, \[
      a^{n} := \begin{cases}
        1_G & n = 0\\
        \underbrace{a \ast \cdots \ast a}_{a \text{ times}} & n > 0\\
        \underbrace{a^{-1} \ast \cdots \ast a^{-1}}_{-n \text{ times}} & n < 0
      \end{cases}
      \]
      Then, $a^{n+m} = a^n a^m$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  \begin{enumerate}
    \item $c = c \ast 1_G = 1_G$
    \item $b = b \ast 1_G = b \ast (a \ast c) = (b \ast a) \ast c = 1_G \ast c = c \implies b = c$
    \item $(a_1a_2)(a_2^{-1}a_1^{-1}) = a_1 a_2^{-1}a_2a_1^{-1} = a_1 1_G a_1^{-1} = a_1 a_1^{-1} = 1_G$. The converse follows.
    \item $ab = ac \implies a^{-1} ab = a^{-1}ac \implies 1_G b = 1_G c \implies b = c$
    \item %TODO: to show
  \end{enumerate}
\end{proof}

\begin{proposition}[What "Doesn't Hold" in Groups]
  \begin{enumerate}
    \item Only one operation, $\ast$.
    \item Typically, $ab \neq ba$, that is, not commutative (see \cref{def:abeliangroup}).
  \end{enumerate}
\end{proposition}

\begin{definition}[Commutative/Abelain Group]\label{def:abeliangroup}
  If $\forall a, b \in G, ab = ba,$ $G$ is called \emph{commutative} or \emph{abelian}. Sometimes, if $G$ abelian, we write the operation as $+$ and the neutral element as $0$.
\end{definition}

\begin{example}[Basic Examples of Groups]
  \begin{itemize}
    \item $G = \{1\}$, where $1 \ast 1 = 1$.
    \item $G = \mathbb{Z}$ or $G = \zmod{n}$, where $\ast = +$. Moreover, if $R$ a ring, then $R$ is an abelian group with addition.
    \item For a field $\mathbb{F}$, $(\mathbb{F}, +)$ is an abelian group, as is $(\mathbb{F}^{\times}, \cdot)$.
    \item If $R$ a ring (need not be commutative), then $R^{\times} = \{u \in R : \exists v \in R, uv = vu = 1\}$ (the units) is a group with multiplication.
    
    \begin{itemize}
      \item $\mathbb{Z}, \mathbb{Z}^{\times} = \{\pm 1\}$ is a group.
      \item $R = M_2 (\mathbb{R})$. The units $R^{\times}$ are all the invertible matrices, that is, with non-zero determinant. $(R, +)$ and $(R, \cdot)$ are both groups.
      \item More generally, $R = M_2(\mathbb{F})$, a ring, has units $R^{\times} = M_2(\mathbb{F})^{\times} =: GL_2 (\mathbb{F})$. Note that this is a non-abelian group under multiplication (as matrix multiplication not commutative).
    \end{itemize}
  \end{itemize}
\end{example}








% \section{Appendix}



% \subsection{Homeworks}

% \subsection{Quiz 1}
% % cheating
% \hspace{1cm}\begin{exercise}
% If the moon is made of blue cheese then 1 = 2.
% \end{exercise}

% \begin{solution}
%   "If" conditionals are true for all cases except when the hypothesis is true and the conclusion is false. In this case, we have $F \to F$, which is \textbf{true}.
% \end{solution}

% \begin{exercise}
%   If the moon is not made of blue cheese then 1=2.
% \end{exercise}

% \begin{solution}
%   $T \to F$, \textbf{false}.
% \end{solution}

% \begin{exercise}
%   If $A,B,C$ are sets, then \[A\setminus(B\setminus C) = (A \setminus B)\setminus C.\]
% \end{exercise}

% \begin{solution}
%   This is essentially asking whether set difference is associative, which it is generally not and thus this is \textbf{false}.

%   We can also prove it directly. Take $x \in \text{ LHS}$. Thus, $x \in A$ but not $x \notin (B \setminus C)$. In order for $x \notin (B \setminus C)$, we must either have (1) $x \notin C$ but $x \in B$, or (2) $x \in B, x \in C$.

%   Consider case (1); $x \in A, B, \notin C$. Thus, $x \notin (A\setminus B)$, and so $x \notin \text{ RHS}$. This alone (I believe?) is proof that the two are not equal, but regardless, let us consider case (2); $x \in A, B, C$. Thus, $x \notin (A \setminus B)$, and so $x \notin \text{ RHS}$. Thus, we have proven that LHS $\nsubseteq$ RHS, and so LHS $\neq$ RHS.
% \end{solution}

% \begin{exercise}
%   If $A,B$ are sets, then \[(A\setminus B) \cap (A \cap B) = A\setminus A.\]
% \end{exercise}

% \begin{solution}
%   Note that $A\setminus A = \varnothing$, ie there exist no elements both in and not in $A$. Thus, we can formulate this question as trying to find whether there exists elements in the LHS. 
  
%   Let's assume $x \in \text{ LHS}$. As LHS is the intersect of two sets, $x$ must be both "sides" of the intersect, ie $x \in (A\setminus B)$ and $x \in (A \cap B)$. By the left of this intersect, $x \in A$ and $x \notin B$, but by the right of this intersect, $x\in A$ AND $x \in B$. Thus, $x \in B$, while simultaneously, $x\notin B$, (same as finding $B \setminus B$, which naturally is the same as $A \setminus A$) which cannot exist and thus the LHS is also $\varnothing$, and the statement is \textbf{true}.
% \end{solution}

% \begin{exercise}
%   Let $I$ be an index set and $A_i$, $B_j$ be sets for $i \in I$. Then \[(\bigcup_{i \in I}A_i) \cap (\bigcup_{i \in I}B_i) = \bigcup_{i \in I}(A_i \cap B_i).\]
% \end{exercise}

% \begin{solution}
%   Intuitively, consider the abstract "size" of both sets. The LHS is the shared elements between all $A_i$ and $B_i$; however, the RHS is the union of all $A_i, B_i$ for specific $i$'s. Thus, the sets are not equal, as consider some $x \in A_i, x \in B_{i+1}$. In the LHS, this element would be included, but would not in the RHS. Thus, the statement is \textbf{false}.
% \end{solution}

% \begin{exercise}
%   Consider the following proof by induction of the statement
%   \[\text{for every integer } n \geq 0, 2^n > 2n.\]
  
%   (1) It is true for $n=0$. (2) Suppose $2^n > 2n$. Then, multiplying both sides by 2, we have $2*2^n > 2*2n \implies 2^{(n+1)} > 4n$. (3) $4n \geq 2(n+1)$, and thus $2^(n+1) > 2(n+1)$. QED.

%   This statement is false; which step is incorrect?
% \end{exercise}

% \begin{solution}
%   \textbf{(3)} is the false step; the assertion that $4n \geq 2(n+1)$ is only true for $n \geq 1$, which is not the same base case as the one given. 
  
%   A correct proof could either be given with a base case $n \geq 3$, or with $P_n$ changed to $2^n \geq 2n$; in which case, the base case would hold for any $n \geq 0$. It is straightforward to prove this new $P_n$ in the $n \geq 1$ case, but slightly more difficult to prove it for $n = 0$, and we need to consider different cases in step (3).\footnote{Notice that, although $2^n \geq 2n \forall n \geq 0$ where $n\in \mathbb{N}$, $2^x \cancel{>} 2x \forall x \geq 0$ when $x \in \mathbb{R}$. This can be clear from graphing the two as functions of $x$, as $2^x = 2x$ at $x\in\{1,2\}$, and $2x > 2^x$ for $x \in (1,2)$}
% \end{solution}

% \begin{exercise}
% The proof by induction above is correct for which statements?
% % TODO: add choices?
% \end{exercise}

% \begin{solution}
%   Discussed briefly above; for $n \geq 1$ and $n \geq 2$, the statement is false as $2^n = 2n$ at these points, and the statement is clearly true for $n \geq 3$ and naturally $n \geq 4$ (since, well, $4 \geq 3$).
% \end{solution}

% \begin{exercise}
%   Let $A = \{1,2,3,4\}, B = \{1,2,3\}$. How many functions $f: A \to B$ are there?
% \end{exercise}

% \begin{solution}
%   Be careful with definitions: a function must have a value $f(a) \in B$ for \textit{all} $a \in A$, thus, every value in $A$ must be "used" in a given function. However, there is no requirement for injectivity/surjectivity (yet), so we may have multiple values in $A$ map to the same value in $B$, BUT, no value in $A$ may map to multiple values in $B$ (as this would violate the definition of a function).

%   Thus, terminology aside, each of the 4 elements must map to one of 3 elements, and so we have $3^4 = \mathbf{81}$ possible functions. Generally, the number of possible functions between two sets ($f: A \to B $) is $|B|^{|A|}.$
% \end{solution}

% \begin{exercise}
%   Using the same sets as above, how many surjective functions $f: A \to B$ are there?
% \end{exercise}

% \begin{solution}
%   We have two conditions to keep in mind for a function to be surjective: (1) \textbf{every} element in $a$ are mapped to a \textbf{single} element in $b$, and (2) every element in $B$ is mapped to by \textbf{at least one} element in $A$. Note that (2) means that multiple elements in $A$ can map to the same element in $B$; however, no element in $A$ can map to multiple elements in $B$ (as this would violate (1)).

%   Clearly, given $|A| = 4, |B|=3$, then elements in $B$ can be mapped to by either 1 or 2 functions (specifically, one element will be mapped to by two elements and the other 2 by just one). Thus, we can consider the different partitions of $A$ such that are possible for each element in $B$ to be mapped. Let us consider $A = \{a,b,c,d\}$ and $B =\{\alpha, \beta, \gamma\}$, for convenience. We have the following partitions:
%   \[
%   \begin{matrix}
%     \alpha & \beta & \gamma\\
%     \{a, b\} & \{c\} & \{d\}\\
%     \{a, c\} & \{b\} & \{d\}\\
%     \{a, d\} & \{b\} & \{c\}\\
%     \{b, c\} & \{a\} & \{d\}\\
%     \{b, d\} & \{a\} & \{c\}\\
%     \{c, d\} & \{a\} & \{b\}\\
%   \end{matrix}  
%   \]
%   We have $6$ partitions, but $\alpha, \beta,$ and $\gamma$ can be rearranged as well, given us $6 \times 3! = \mathbf{36}$ different surjective functions.
% \end{solution}

% \begin{exercise}
%   Using the same sets as above, how many injective functions $f: A \to B$ are there?
% \end{exercise}

% \begin{solution}
%   Recall that an injective function must "uniquely" assign elements of $b$ to elements of $a$, ie, $f(a_1)=f(a_2) \implies a_1=a_2$. We thus have a pigeonhole problem, as there are more elements "to-be-mapped" (in $A$) than can be mapped to (in $B$). Thus, there are \textbf{$0$} injective functions.

%   You can also reason this by the fact that if an injective function $f: A\to B$ exists, then $|A| \leq |B|$, and as $|A| > |B|$, no such function can exist.
% \end{solution}

% \begin{exercise}
%   Given $(-r, r) = \{x \in \mathbb{R} : -r < x < r\}$ and $[-r,r] = \{x \in \mathbb{R} : -r \leq x \leq r\}$, what is $\bigcup_{r > 1} (-r, r)$?
% \end{exercise}

% \begin{solution}
%   In "non-math" words, this is asking what is the set of shared elements in all $(-r, r)$ for $r > 1$. Clearly, every "iteration" of the intersection will add more elements, none of which will be in the previous sets (ie, $(-2, 2)$ and $(-(2 + \epsilon), 2 + \epsilon)$; the only elements \textit{not} shared will be $-(2 + \epsilon)$ and $2+\epsilon$), and thus the intersection must be $\mathbf{[-1,1]}$. Note that the intersection does indeed include $\{-1,1\}$ (it is inclusive) since the union is over $r > 1$, thus the set $(-1,1)$ is never included in the union and thus $\{-1,1\}$ is always present in every $(-r,r)$.
% \end{solution}

% \begin{exercise}
%   For a positive real $r$, let $A_r = (-2r, 2r)\setminus \{-r,r,0\}$. What is $(\bigcup_{r>0}A_r)\setminus (\bigcap_{r > 0}A_r)$?
% \end{exercise}

% \begin{solution}
%   To begin with, it should be clear that $A_r$ will never contain $0$, and as a result neither will $\bigcup A_r$, and thus $0$ will not in the final set. The only option without $0$ is the correct answer $\mathbf{\mathbb{R}\setminus \{0\}}$, which you can also verify directly.
% \end{solution}
\end{document}