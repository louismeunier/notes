\begin{definition}[Eigenbasis]
    Call a basis consisting of eigenvectors of an operator $T$ an \emph{eigenbasis} of $T$.
\end{definition}

\begin{theorem}[Diagonalizability of Normal Operators]
    Let $T : V\to V$ on $V$ finite dimensional over $\C$. Then, $T$ is normal iff there is an orthonormal eigenbasis for $T$.
\end{theorem}

\begin{lemma}
    % TODO
\end{lemma}

\begin{proof}
    ($\implies$) Suppose $T$ is normal, hence the eigenvectors of $T$ and $T^\ast$ are the same by \cref{prop:propertiesofnormaloperators}. Because $\field  = \C$, all polynomials split so in particular $p_T(t)$ splits, and applying precisely the same proof of \cref{lemma:schurs} with inductive assumption that there is an orthonormal basis such that the matrix diagonal (rather than upper triangular). In the inductive step, we put $W \defeq \Span (\{v_n\})$, and have $W^\perp$ $T$-invariant and $n - 1$ dimensional, and $T_{W^\perp}$ is normal by lemma above. Hence, the inductive hypothesis applies to $T_{W^\perp}$, yielding an orthonormal eigenbasis $\beta'$ for $W^\perp$, and  with $\beta \defeq \beta \cup \{v_n\}$, since each $v_n$ also an eigenvector of $T$, $[Tv_n]_\beta = \begin{pmatrix}
        0 \\
        \vdots\\
        0\\
        \star
    \end{pmatrix}$, so $\beta$ an orthonormal eigenbasis.

    ($\impliedby$) Suppose $\beta$ an orthonormal eigenbasis, then $[T]_\beta$ is diagonal and $[T^\ast]_\beta = [T]_\beta^\ast$ is also diagonal. But diagonal matrices commute, so \[
    [T \circ T^\ast]_\beta = [T]_\beta \cdot [T^\ast]_\beta = [T^\ast]_\beta \cdot [T]_\beta = [T^\ast \circ T]_\beta,    
    \]
    so $T\circ T^\ast = T^\ast \circ T$, ie, $T$ is normal.
\end{proof}

In particular, this gives that self-adjoint operators on complex inner products admit an orthonormal eigenbasis; what about over $\R$? What condition do we need to impose then?

\begin{lemma}
    The eigenvalues of self-adjoint operators, even on complex inner product spaces, are real.
\end{lemma}

\begin{proof}
    Let $T$ be self-adjoint, $\lambda$ an eigenvalue and $v$ a corresponding eigenvector. $T$ normal gives $v$ also an eigenvector of $T^\ast$ corresponding to $\overline{\lambda}$. Thus, $\lambda v = Tv = T^\ast v = \overline{\lambda}v$, hence $(\lambda - \overline{\lambda})v = 0_V$. But $v \neq 0_V$ hence $\lambda = \overline{\lambda}$ and so $\lambda \in \R$.
\end{proof}

\begin{lemma}
    Characteristic polynomials of real symmetric matrices split over $\R$ .
\end{lemma}

\begin{proof}
    Let $A \in M_n(\R)$ be a symmetric matrix, ie $A = A^t$, hence $A = A^\ast$ (since $A^\ast = \overline{A}^t = A^t$, since all entries are real). Let $L_A : \C^n \to \C^n$ denote the usual multiplication by $A$. Then, $L_A^\ast = L_{A^\ast} = L_A$, so $L_A$ itself a self-adjoint operator on $\C^n$ (with inner product given by the dot product). Then, $p_{L_A}(t)$ splits over $\C$ and the roots of $p_{L_A}(t)$ are real because $L_A$ self-adjoint, by the previous lemma. Hence, $p_{L_A}(t)$ splits over $\R$ as well. But, letting $\beta$ be the standard basis for $\C^n$, we have $p_{L_A}(t) = p_{[L_A]_\beta}(t) = p_A(t)$, so $p_A(t)$ itself splits over $\R$.
\end{proof}

\begin{corollary}
    Let $T : V \to V$ be self-adjoint for $V$ over $\R$. Then, $p_T(t)$ splits over $\R$.
\end{corollary}
\begin{proof}
    Let $\beta$ be an orthonormal basis for $V$, then $A \defeq [T]_\beta$ is real and $A^t = A^\ast = [T]_\beta^\ast = [T^\ast]_\beta = [T]_\beta = A$, so $A$ symmetric. Then, $p_T(t) \defeq p_{[T]_\beta}(t) = p_A(t)$ splits over $\R$ by the previous lemma.
\end{proof}

\begin{theorem}[Diagonalizability of Self-Adjoint Operators over $\R$]
    Let $T : V \to V$ be a linear operator on a finite-dimensional inner product space $V$ over $\field \defeq \R$. Then, $T$ self-adjoint iff  there is an orthonormal eigenbasis for $T$.
\end{theorem}

\begin{proof}
    $(\implies)$ Suppose $T$ self-adjoint. Then, $p_T(t)$ splits over $\R$ by the previous corollary, so Schur's (\cref{lemma:schurs}) applies, yielding an orthonormal basis $\beta$ for $V$ \st $[T]_\beta$ is upper triangular, hence $[T]_\beta^t$ lower triangular. But $[T]_\beta^t = [T]^\ast_\beta$ (over reals) $ = [T^\ast]_\beta = [T]_\beta$ is upper triangular, so $[T]_\beta$ must be diagonal so $\beta$ an orthonormal eigenbasis.

    ($\impliedby$) Suppose that there is an orthonormal basis for $T$. Then $[T]_\beta$ is a real diagonal matrix, hence $[T^\ast]_\beta = [T]_\beta^\ast = [T]_\beta^t = [T]_\beta$, and thus $T^\ast = T$.
\end{proof}

\begin{theorem}[Spectral Theorem (for normal/self adjoint operators)]\label{thm:spectral}
    Let $T : V \to V$ on a finite dimensional inner product space $V$ over $\field$. If $\field = \C$, then suppose $T$ is normal, and if $\field = \R$, suppose that $T$ is self-adjoint. Then, $T$ admits a unique (up to reindexing) \emph{spectral decomposition}, ie \[
    T = \lambda_1 P_1 + \lambda_2 P_2 + \cdots + \lambda_k P_3,
    \]
    where the $P_i$ are orthogonal projections such that $I_V = P_1 + \cdots + P_k$ and $P_i \circ P_j = \delta_{ij} P_{j}$. In other words, $V = \bigoplus_{i=1}^k \im(P_i)$ and the images $\im(P_i) \perp \im(P_j)$ for $i \neq j$.
\end{theorem}